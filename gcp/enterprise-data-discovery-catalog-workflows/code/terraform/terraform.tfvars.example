# Example Terraform variables file for Enterprise Data Discovery
# Copy this file to terraform.tfvars and customize for your environment

# REQUIRED: Google Cloud Project Configuration
project_id = "your-gcp-project-id"
region     = "us-central1"
zone       = "us-central1-a"

# Resource Naming and Organization
resource_prefix = "data-discovery"
environment     = "dev"

# Scheduling Configuration (times in UTC)
scheduler_config = {
  daily_schedule   = "0 2 * * *"           # 2 AM UTC daily
  weekly_schedule  = "0 1 * * 0"           # 1 AM UTC Sunday
  time_zone       = "America/New_York"     # Adjust to your timezone
  description     = "Automated enterprise data discovery"
}

# Cloud Function Configuration
function_config = {
  name          = "metadata-extractor"
  runtime       = "python311"
  memory        = "1Gi"                    # Increase for large datasets
  timeout       = 540                     # 9 minutes (max for gen2)
  max_instances = 10                      # Scale for concurrent requests
  min_instances = 0                       # Keep instances warm if needed
}

# Workflow Configuration
workflow_config = {
  name        = "data-discovery-workflow"
  description = "Orchestrates automated data discovery and cataloging"
}

# Resource Labels for Organization
labels = {
  project     = "enterprise-data-discovery"
  managed_by  = "terraform"
  team        = "data-engineering"
  environment = "dev"
  cost_center = "engineering"
}

# IAM Roles for Service Account (customize as needed)
service_account_roles = [
  "roles/datacatalog.admin",
  "roles/bigquery.dataViewer",
  "roles/storage.objectViewer",
  "roles/cloudsql.viewer",
  "roles/logging.logWriter",
  "roles/monitoring.metricWriter"
]

# Sample BigQuery Datasets Configuration
# Customize or set to {} to skip sample data creation
sample_datasets = {
  customer_analytics = {
    description   = "Sample customer data for discovery testing"
    location     = "US"
    friendly_name = "Customer Analytics"
    tables = {
      transactions = {
        description = "Customer transaction history"
        schema = [
          { name = "customer_id", type = "STRING" },
          { name = "transaction_date", type = "TIMESTAMP" },
          { name = "amount", type = "FLOAT64" },
          { name = "product_category", type = "STRING" },
          { name = "payment_method", type = "STRING" }
        ]
      }
      customers = {
        description = "Customer profile information"
        schema = [
          { name = "customer_id", type = "STRING" },
          { name = "first_name", type = "STRING" },
          { name = "last_name", type = "STRING" },
          { name = "email", type = "STRING" },
          { name = "registration_date", type = "DATE" },
          { name = "status", type = "STRING" }
        ]
      }
    }
  }
  hr_internal = {
    description   = "Internal employee data for testing"
    location     = "US"
    friendly_name = "HR Internal"
    tables = {
      employees = {
        description = "Employee personal information"
        schema = [
          { name = "employee_id", type = "STRING" },
          { name = "first_name", type = "STRING" },
          { name = "last_name", type = "STRING" },
          { name = "email", type = "STRING" },
          { name = "department", type = "STRING" },
          { name = "salary", type = "INTEGER" },
          { name = "hire_date", type = "DATE" }
        ]
      }
    }
  }
}

# Sample Cloud Storage Buckets Configuration
# Customize or set to {} to skip sample bucket creation
storage_buckets = {
  public_datasets = {
    location      = "US"
    storage_class = "STANDARD"
    description   = "Public datasets for testing discovery"
    versioning    = false
    sample_files = {
      "sample-public-data.txt" = "Sample public dataset content for discovery testing"
      "readme.md" = "# Public Datasets\nThis bucket contains public datasets for testing."
    }
  }
  confidential_reports = {
    location      = "US"
    storage_class = "STANDARD"
    description   = "Confidential reports for sensitivity testing"
    versioning    = true
    sample_files = {
      "financial-report-q4.txt" = "Confidential financial report data for classification testing"
      "employee-data.csv" = "employee_id,department,salary\n001,Engineering,95000"
    }
  }
  archive_data = {
    location      = "US"
    storage_class = "COLDLINE"
    description   = "Archive data for long-term storage testing"
    versioning    = false
    sample_files = {
      "archive-2023.json" = "{\"year\": 2023, \"archived\": true, \"records\": 50000}"
    }
  }
}

# Data Catalog Tag Templates Configuration
# Customize classification schemas for your organization
tag_templates = {
  data_classification = {
    display_name = "Data Classification Template"
    description  = "Template for classifying data sensitivity and ownership"
    fields = {
      sensitivity = {
        display_name = "Data Sensitivity"
        type         = "ENUM"
        is_required  = true
        enum_values  = ["PUBLIC", "INTERNAL", "CONFIDENTIAL", "RESTRICTED"]
      }
      owner = {
        display_name = "Data Owner"
        type         = "STRING"
        is_required  = true
      }
      department = {
        display_name = "Department"
        type         = "STRING"
        is_required  = false
      }
      last_updated = {
        display_name = "Last Updated"
        type         = "DATETIME"
        is_required  = false
      }
    }
  }
  data_quality = {
    display_name = "Data Quality Metrics"
    description  = "Template for tracking data quality metrics and validation status"
    fields = {
      completeness_score = {
        display_name = "Completeness Score"
        type         = "DOUBLE"
        is_required  = false
      }
      accuracy_score = {
        display_name = "Accuracy Score"
        type         = "DOUBLE"
        is_required  = false
      }
      freshness_days = {
        display_name = "Data Freshness (Days)"
        type         = "DOUBLE"
        is_required  = false
      }
      validation_date = {
        display_name = "Last Validation"
        type         = "DATETIME"
        is_required  = false
      }
    }
  }
}

# Industry-specific tag template examples (uncomment and customize as needed)

# GDPR Compliance Template
# gdpr_compliance = {
#   display_name = "GDPR Compliance Classification"
#   description  = "Template for GDPR compliance tracking"
#   fields = {
#     personal_data = {
#       display_name = "Contains Personal Data"
#       type         = "ENUM"
#       is_required  = true
#       enum_values  = ["YES", "NO", "UNKNOWN"]
#     }
#     lawful_basis = {
#       display_name = "Lawful Basis for Processing"
#       type         = "STRING"
#       is_required  = false
#     }
#     retention_period = {
#       display_name = "Data Retention Period (Months)"
#       type         = "DOUBLE"
#       is_required  = false
#     }
#   }
# }

# HIPAA Compliance Template
# hipaa_compliance = {
#   display_name = "HIPAA Data Classification"
#   description  = "Template for HIPAA-regulated healthcare data"
#   fields = {
#     phi_status = {
#       display_name = "PHI Status"
#       type         = "ENUM"
#       is_required  = true
#       enum_values  = ["NON_PHI", "LIMITED_PHI", "FULL_PHI", "DE_IDENTIFIED"]
#     }
#     covered_entity = {
#       display_name = "Covered Entity"
#       type         = "STRING"
#       is_required  = false
#     }
#   }
# }