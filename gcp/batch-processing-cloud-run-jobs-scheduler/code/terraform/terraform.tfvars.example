# Example Terraform variables configuration
# Copy this file to terraform.tfvars and customize for your environment

# Required: Google Cloud Project Configuration
project_id = "your-project-id-here"
region     = "us-central1"
zone       = "us-central1-a"

# Resource Naming Configuration
resource_prefix = "batch-processing"
environment     = "dev"

# Artifact Registry Configuration
registry_repository_id = "batch-registry"
registry_format        = "DOCKER"

# Cloud Storage Configuration
bucket_name          = ""  # Leave empty for auto-generated name
bucket_location      = "US"
bucket_storage_class = "STANDARD"

# Cloud Run Job Configuration
job_name         = "data-processor"
job_task_count   = 1
job_parallelism  = 1
job_task_timeout = 3600  # 1 hour in seconds
job_max_retries  = 3
job_cpu          = "1"
job_memory       = "2Gi"

# Container Image Configuration
# Leave empty to use auto-generated image from Artifact Registry
container_image = ""

# Cloud Scheduler Configuration
scheduler_job_name      = "batch-schedule"
scheduler_cron_schedule = "0 * * * *"  # Every hour
scheduler_timezone      = "America/New_York"
scheduler_description   = "Automated batch processing job execution"

# Environment Variables for Batch Processing
batch_environment_variables = {
  BATCH_SIZE      = "10"
  LOG_LEVEL       = "INFO"
  PROCESSING_MODE = "standard"
}

# Service Account Configuration
service_account_id           = "batch-processor-sa"
service_account_display_name = "Batch Processor Service Account"
service_account_description  = "Service account for batch processing Cloud Run jobs"

# Monitoring Configuration
enable_monitoring    = true
log_retention_days   = 30

# API Services to Enable
enable_apis = [
  "cloudbuild.googleapis.com",
  "artifactregistry.googleapis.com",
  "run.googleapis.com",
  "cloudscheduler.googleapis.com",
  "storage.googleapis.com",
  "logging.googleapis.com",
  "monitoring.googleapis.com",
  "iam.googleapis.com",
  "cloudresourcemanager.googleapis.com"
]

# Resource Labels
labels = {
  environment = "dev"
  team        = "data-engineering"
  project     = "batch-processing"
  managed-by  = "terraform"
  cost-center = "engineering"
}

# Network Configuration (Optional)
network_name = "default"
subnet_name  = "default"

# Build Configuration
build_timeout     = 600  # 10 minutes
build_machine_type = "E2_STANDARD_2"

# Example configurations for different environments:

# Development Environment
# environment = "dev"
# job_cpu = "0.5"
# job_memory = "1Gi"
# enable_monitoring = false
# scheduler_cron_schedule = "0 */6 * * *"  # Every 6 hours

# Staging Environment
# environment = "staging"
# job_cpu = "1"
# job_memory = "2Gi"
# enable_monitoring = true
# scheduler_cron_schedule = "0 */2 * * *"  # Every 2 hours

# Production Environment
# environment = "prod"
# job_cpu = "2"
# job_memory = "4Gi"
# enable_monitoring = true
# scheduler_cron_schedule = "0 1 * * *"  # Daily at 1 AM
# job_max_retries = 5
# bucket_location = "US"
# bucket_storage_class = "STANDARD"

# High-Performance Configuration
# job_cpu = "8"
# job_memory = "16Gi"
# job_parallelism = 10
# job_task_count = 100
# build_machine_type = "E2_STANDARD_16"

# Cost-Optimized Configuration
# job_cpu = "0.25"
# job_memory = "512Mi"
# bucket_storage_class = "NEARLINE"
# enable_monitoring = false
# scheduler_cron_schedule = "0 2 * * 0"  # Weekly on Sunday at 2 AM