# ================================================================
# Example Terraform Variables Configuration
# 
# Copy this file to terraform.tfvars and customize the values
# for your specific deployment requirements.
# 
# cp terraform.tfvars.example terraform.tfvars
# ================================================================

# ----------------------------------------------------------------
# Required Configuration (Must be provided)
# ----------------------------------------------------------------

# Your Google Cloud Project ID
project_id = "your-project-id-here"

# ----------------------------------------------------------------
# Basic Configuration
# ----------------------------------------------------------------

# Google Cloud region and zone (must support TPU Ironwood)
region = "us-central1"
zone   = "us-central1-a"

# Environment identifier
environment = "development"

# ----------------------------------------------------------------
# GKE Cluster Configuration
# ----------------------------------------------------------------

# GKE cluster settings
cluster_name              = "tpu-ironwood-cluster"
cluster_ipv4_cidr        = "10.1.0.0/16"
services_ipv4_cidr       = "10.2.0.0/16"
maintenance_start_time   = "03:00"

# ----------------------------------------------------------------
# Node Pool Configuration
# ----------------------------------------------------------------

# Standard node pool (for system components)
standard_machine_type = "e2-standard-4"
standard_node_count   = 2
standard_min_nodes    = 1
standard_max_nodes    = 10

# TPU node pool (for inference workloads)
tpu_machine_type      = "n1-standard-8"
tpu_accelerator_type  = "tpu-v7-pod-slice"
tpu_accelerator_count = 8
tpu_node_count        = 1
tpu_min_nodes         = 0
tpu_max_nodes         = 3

# ----------------------------------------------------------------
# Storage Configuration
# ----------------------------------------------------------------

# Cloud Storage bucket for model artifacts
bucket_name_prefix = "llm-models"

# Parallelstore for high-performance model storage
parallelstore_name            = "model-storage"
parallelstore_capacity_gib    = 1024
parallelstore_performance_tier = "SSD"

# ----------------------------------------------------------------
# IAM and Security Configuration
# ----------------------------------------------------------------

# Service account configuration
service_account_name = "tpu-inference-sa"

# Kubernetes workload identity configuration
k8s_namespace       = "default"
k8s_service_account = "tpu-inference-pod"

# ----------------------------------------------------------------
# Model Configuration
# ----------------------------------------------------------------

# Model metadata for organization
model_name    = "llm-7b"
model_version = "v1.0"

# ----------------------------------------------------------------
# Feature Flags
# ----------------------------------------------------------------

# Enable/disable optional features
enable_cost_optimization = true
enable_monitoring        = true
enable_network_policy    = true
deletion_protection      = false

# ----------------------------------------------------------------
# Custom Labels (Optional)
# ----------------------------------------------------------------

# Additional labels for resource organization
custom_labels = {
  team        = "ml-engineering"
  cost-center = "research"
  application = "llm-inference"
}

# ----------------------------------------------------------------
# Advanced Configuration (Optional)
# ----------------------------------------------------------------

# Additional taints for TPU node pool
node_pool_taints = [
  {
    key    = "workload-type"
    value  = "ml-inference"
    effect = "NO_SCHEDULE"
  }
]

# ----------------------------------------------------------------
# Example Production Configuration
# ----------------------------------------------------------------

# Uncomment and modify for production deployments:

# project_id = "production-ml-project"
# environment = "production"
# region = "us-central1"
# zone = "us-central1-a"

# cluster_name = "prod-tpu-inference-cluster"
# standard_machine_type = "n2-standard-8"
# standard_node_count = 3
# standard_min_nodes = 2
# standard_max_nodes = 20

# tpu_machine_type = "n1-standard-16"
# tpu_accelerator_count = 16
# tpu_node_count = 2
# tpu_min_nodes = 1
# tpu_max_nodes = 5

# parallelstore_capacity_gib = 4096
# parallelstore_performance_tier = "SSD"

# deletion_protection = true
# enable_network_policy = true

# custom_labels = {
#   environment = "production"
#   team = "ml-platform"
#   cost-center = "engineering"
#   compliance = "sox"
# }

# ----------------------------------------------------------------
# Example Development Configuration
# ----------------------------------------------------------------

# Uncomment for development/testing deployments:

# project_id = "dev-ml-experiments"
# environment = "development"

# # Smaller cluster for development
# standard_machine_type = "e2-standard-2"
# standard_node_count = 1
# standard_min_nodes = 1
# standard_max_nodes = 3

# # Minimal TPU configuration
# tpu_accelerator_count = 2
# tpu_node_count = 1
# tpu_min_nodes = 0
# tpu_max_nodes = 1

# # Smaller storage for cost savings
# parallelstore_capacity_gib = 1024
# parallelstore_performance_tier = "HDD"

# enable_cost_optimization = true
# deletion_protection = false

# ----------------------------------------------------------------
# Regional Configuration Examples
# ----------------------------------------------------------------

# US East Coast (Virginia)
# region = "us-east1"
# zone = "us-east1-b"

# Europe (Belgium)
# region = "europe-west1"
# zone = "europe-west1-b"

# Asia Pacific (Tokyo)
# region = "asia-northeast1"
# zone = "asia-northeast1-a"

# ----------------------------------------------------------------
# Cost Optimization Examples
# ----------------------------------------------------------------

# For cost-sensitive development environments:
# - Use HDD Parallelstore tier
# - Enable preemptible instances where possible
# - Set aggressive autoscaling minimums
# - Use smaller machine types
# - Enable all cost optimization features

# enable_cost_optimization = true
# parallelstore_performance_tier = "HDD"
# tpu_min_nodes = 0
# standard_min_nodes = 1