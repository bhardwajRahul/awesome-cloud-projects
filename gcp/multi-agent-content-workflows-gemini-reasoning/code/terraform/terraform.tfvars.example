# =============================================================================
# Terraform Variables Example for Multi-Agent Content Workflows
# =============================================================================
# Copy this file to terraform.tfvars and customize the values for your deployment.
# This file provides examples and guidance for all configurable parameters.
# =============================================================================

# Project Configuration
# -----------------------------------------------------------------------------
# REQUIRED: Your Google Cloud Project ID
project_id = "your-project-id-here"

# REQUIRED: GCP region for resource deployment
# Choose a region that supports Vertex AI and has good latency for your users
region = "us-central1"  # Options: us-central1, us-east1, europe-west1, asia-east1

# Resource Labels for Organization and Cost Tracking
# -----------------------------------------------------------------------------
labels = {
  environment   = "development"          # development, staging, production
  project      = "content-intelligence"  # Your project name
  managed-by   = "terraform"            # Resource management method
  component    = "multi-agent-workflows" # Component identifier
  cost-center  = "ai-ml"                # Cost allocation
  owner        = "data-team"            # Team responsible
  purpose      = "content-analysis"      # Business purpose
}

# Cloud Function Configuration
# -----------------------------------------------------------------------------
function_config = {
  memory        = "512Mi"    # 128Mi, 256Mi, 512Mi, 1Gi, 2Gi, 4Gi, 8Gi
  timeout       = 540        # Max 540 seconds (9 minutes)
  max_instances = 10         # Maximum concurrent function instances
  min_instances = 0          # Minimum instances (0 for cost optimization)
}

# Vertex AI and Gemini Configuration
# -----------------------------------------------------------------------------
gemini_model_config = {
  model_version     = "gemini-2.5-pro"           # Latest Gemini model
  default_temperature = 0.1                      # Lower for more deterministic output
  max_output_tokens  = 4096                      # Maximum response length
  safety_threshold   = "BLOCK_MEDIUM_AND_ABOVE"  # Content safety level
}

# Content Processing Configuration
# -----------------------------------------------------------------------------
content_processing_config = {
  # Supported file formats for each content type
  supported_text_formats  = ["txt", "md", "csv", "json", "pdf", "docx"]
  supported_image_formats = ["jpg", "jpeg", "png", "gif", "bmp", "webp"]
  supported_video_formats = ["mp4", "avi", "mov", "wmv", "webm"]
  
  # File size limit in MB (adjust based on your needs and costs)
  max_file_size_mb = 100
  
  # Enable advanced processing features
  enable_ocr             = true   # Optical Character Recognition for images
  enable_speech_to_text  = true   # Speech recognition for video/audio
}

# Storage Configuration
# -----------------------------------------------------------------------------
storage_config = {
  storage_class           = "STANDARD"  # STANDARD, NEARLINE, COLDLINE, ARCHIVE
  enable_versioning      = true        # Keep file versions
  lifecycle_age_nearline = 90          # Days before moving to NEARLINE
  lifecycle_age_coldline = 365         # Days before moving to COLDLINE
  uniform_bucket_access  = true        # Simplified access control
}

# Security and Compliance Configuration
# -----------------------------------------------------------------------------
security_config = {
  enable_audit_logs        = true         # Enable audit logging
  enable_vpc_flow_logs     = true         # VPC flow logs for network monitoring
  enable_private_google_access = true     # Private Google API access
  allowed_ip_ranges        = ["0.0.0.0/0"] # Restrict to specific IPs in production
  enable_cmek             = false         # Customer-managed encryption keys
}

# Monitoring and Alerting Configuration
# -----------------------------------------------------------------------------
monitoring_config = {
  enable_alerts           = true   # Enable monitoring alerts
  notification_channels   = []     # Add notification channel IDs here
  alert_threshold_errors  = 5      # Error count threshold for alerts
  alert_threshold_latency = 10000  # Latency threshold in milliseconds
  log_retention_days     = 30      # Log retention period
}

# Workflow Configuration
# -----------------------------------------------------------------------------
workflow_config = {
  execution_timeout_seconds = 3600      # 1 hour max execution time
  max_concurrent_executions = 100       # Maximum parallel workflows
  enable_call_log_level     = "ALL_CALLS" # Logging level: NO_CALLS_LOG, ERRORS_ONLY, ALL_CALLS
  retry_policy_max_attempts = 3         # Maximum retry attempts for failed steps
}

# Optional Features
# -----------------------------------------------------------------------------
# Enable Data Loss Prevention for sensitive content detection
enable_dlp = false

# Create sample content for testing the workflow
create_sample_content = true

# Create dedicated VPC network for enhanced security
create_dedicated_network = false

# Cost Management Configuration
# -----------------------------------------------------------------------------
cost_management = {
  budget_amount_usd          = 1000              # Monthly budget in USD
  budget_alert_thresholds    = [0.5, 0.8, 1.0]  # Alert at 50%, 80%, 100%
  enable_committed_use       = false             # Committed use discounts
  enable_preemptible_instances = false           # Use preemptible instances
}

# Processing Limits and Quotas
# -----------------------------------------------------------------------------
processing_limits = {
  max_requests_per_minute    = 60     # Rate limiting
  max_concurrent_workflows   = 10     # Concurrent workflow limit
  max_file_processing_time   = 1800   # 30 minutes max per file
  batch_processing_size      = 5      # Files per batch
}

# AI Agent Configuration
# -----------------------------------------------------------------------------
agent_configurations = {
  text_agent = {
    temperature      = 0.2    # Creativity level for text analysis
    max_tokens      = 2048    # Maximum tokens per analysis
    confidence_threshold = 0.8 # Minimum confidence for results
  }
  image_agent = {
    temperature      = 0.3    # Creativity level for image analysis
    max_features    = 20      # Maximum features to detect
    confidence_threshold = 0.7 # Minimum confidence for results
  }
  video_agent = {
    temperature      = 0.3    # Creativity level for video analysis
    sample_rate     = 16000   # Audio sample rate for processing
    confidence_threshold = 0.75 # Minimum confidence for results
  }
}

# Environment Configuration
# -----------------------------------------------------------------------------
environment = "development"  # development, staging, production

# =============================================================================
# Deployment Examples by Use Case
# =============================================================================

# Example 1: Development Environment
# Optimized for testing and experimentation with lower costs
/*
environment = "development"
function_config = {
  memory        = "256Mi"
  timeout       = 300
  max_instances = 3
  min_instances = 0
}
cost_management = {
  budget_amount_usd = 200
  budget_alert_thresholds = [0.7, 0.9, 1.0]
  enable_committed_use = false
  enable_preemptible_instances = true
}
*/

# Example 2: Production Environment
# Optimized for performance and reliability with higher limits
/*
environment = "production"
function_config = {
  memory        = "1Gi"
  timeout       = 540
  max_instances = 50
  min_instances = 2
}
security_config = {
  enable_audit_logs = true
  enable_vpc_flow_logs = true
  enable_private_google_access = true
  allowed_ip_ranges = ["10.0.0.0/8", "172.16.0.0/12"]  # Restrict to internal networks
  enable_cmek = true
}
create_dedicated_network = true
enable_dlp = true
*/

# Example 3: High-Volume Processing
# Optimized for large-scale content processing
/*
processing_limits = {
  max_requests_per_minute = 300
  max_concurrent_workflows = 50
  max_file_processing_time = 3600
  batch_processing_size = 20
}
workflow_config = {
  execution_timeout_seconds = 7200
  max_concurrent_executions = 500
  enable_call_log_level = "ERRORS_ONLY"
  retry_policy_max_attempts = 5
}
*/

# =============================================================================
# Cost Optimization Tips
# =============================================================================
# 1. Set appropriate file size limits to control AI API costs
# 2. Use lifecycle policies to move old content to cheaper storage
# 3. Enable preemptible instances for non-critical workloads
# 4. Monitor and set budget alerts to prevent overspending
# 5. Use minimum function instances of 0 for development
# 6. Implement content filtering to process only relevant files
# 7. Consider regional deployment to reduce data transfer costs

# =============================================================================
# Security Best Practices
# =============================================================================
# 1. Restrict IP ranges to your organization's networks
# 2. Enable all audit logging for compliance
# 3. Use customer-managed encryption keys (CMEK) for sensitive data
# 4. Create dedicated VPC for production environments
# 5. Enable DLP for sensitive content detection
# 6. Regularly rotate service account keys
# 7. Implement least-privilege access principles
# 8. Monitor and alert on suspicious activities

# =============================================================================
# Performance Tuning Guidelines
# =============================================================================
# 1. Increase function memory for faster processing
# 2. Adjust agent confidence thresholds based on accuracy needs
# 3. Optimize batch sizes for your content volume
# 4. Set appropriate timeout values for your content types
# 5. Monitor workflow execution times and optimize accordingly
# 6. Use appropriate storage classes for your access patterns
# 7. Consider regional deployment for better latency