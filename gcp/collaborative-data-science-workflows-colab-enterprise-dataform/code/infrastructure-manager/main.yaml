# Infrastructure Manager Configuration for Collaborative Data Science Workflows
# This configuration deploys Colab Enterprise, Dataform, BigQuery, and Cloud Storage
# for collaborative data science and ML workflows

# Import block for Google Cloud provider
imports:
  - path: google-cloud-platform

# Global variables for consistent naming and configuration
variables:
  project_id:
    type: string
    description: Google Cloud Project ID
    required: true
  
  region:
    type: string
    description: Primary region for regional resources
    default: "us-central1"
  
  zone:
    type: string
    description: Primary zone for zonal resources
    default: "us-central1-a"
  
  resource_suffix:
    type: string
    description: Suffix for unique resource naming
    default: "collab"
  
  enable_apis:
    type: boolean
    description: Whether to enable required Google Cloud APIs
    default: true
  
  storage_class:
    type: string
    description: Cloud Storage bucket storage class
    default: "STANDARD"
    enum:
      - "STANDARD"
      - "NEARLINE"
      - "COLDLINE"
      - "ARCHIVE"

# Resource definitions
resources:
  # Enable required Google Cloud APIs
  enable_compute_api:
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project_id.value)/services/compute.googleapis.com
      parent: projects/$(ref.project_id.value)
    metadata:
      dependsOn:
        - project_id

  enable_storage_api:
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project_id.value)/services/storage.googleapis.com
      parent: projects/$(ref.project_id.value)
    metadata:
      dependsOn:
        - project_id

  enable_bigquery_api:
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project_id.value)/services/bigquery.googleapis.com
      parent: projects/$(ref.project_id.value)
    metadata:
      dependsOn:
        - project_id

  enable_dataform_api:
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project_id.value)/services/dataform.googleapis.com
      parent: projects/$(ref.project_id.value)
    metadata:
      dependsOn:
        - project_id

  enable_aiplatform_api:
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project_id.value)/services/aiplatform.googleapis.com
      parent: projects/$(ref.project_id.value)
    metadata:
      dependsOn:
        - project_id

  enable_notebooks_api:
    type: gcp-types/serviceusage-v1:services
    properties:
      name: projects/$(ref.project_id.value)/services/notebooks.googleapis.com
      parent: projects/$(ref.project_id.value)
    metadata:
      dependsOn:
        - project_id

  # Cloud Storage bucket for data lake and artifacts
  data_lake_bucket:
    type: gcp-types/storage-v1:buckets
    properties:
      name: ds-workflow-$(ref.resource_suffix.value)-$(uniqueId)
      location: $(ref.region.value)
      storageClass: $(ref.storage_class.value)
      versioning:
        enabled: true
      uniformBucketLevelAccess:
        enabled: true
      publicAccessPrevention: "enforced"
      iamConfiguration:
        uniformBucketLevelAccess:
          enabled: true
      lifecycle:
        rule:
          - action:
              type: "SetStorageClass"
              storageClass: "NEARLINE"
            condition:
              age: 30
              matchesStorageClass:
                - "STANDARD"
          - action:
              type: "SetStorageClass"
              storageClass: "COLDLINE"
            condition:
              age: 365
              matchesStorageClass:
                - "NEARLINE"
    metadata:
      dependsOn:
        - enable_storage_api

  # Create folder structure in Cloud Storage (using objects as placeholders)
  raw_data_folder:
    type: gcp-types/storage-v1:objects
    properties:
      name: "raw-data/.keep"
      bucket: $(ref.data_lake_bucket.name)
      contentType: "text/plain"
    metadata:
      dependsOn:
        - data_lake_bucket

  processed_data_folder:
    type: gcp-types/storage-v1:objects
    properties:
      name: "processed-data/.keep"
      bucket: $(ref.data_lake_bucket.name)
      contentType: "text/plain"
    metadata:
      dependsOn:
        - data_lake_bucket

  model_artifacts_folder:
    type: gcp-types/storage-v1:objects
    properties:
      name: "model-artifacts/.keep"
      bucket: $(ref.data_lake_bucket.name)
      contentType: "text/plain"
    metadata:
      dependsOn:
        - data_lake_bucket

  # BigQuery dataset for analytics
  analytics_dataset:
    type: gcp-types/bigquery-v2:datasets
    properties:
      datasetId: analytics_$(ref.resource_suffix.value)
      projectId: $(ref.project_id.value)
      location: $(ref.region.value)
      description: "Analytics dataset for collaborative data science workflows"
      friendlyName: "Collaborative Analytics Dataset"
      access:
        - role: "OWNER"
          userByEmail: "$(ref.project_id.value)@$(ref.project_id.value).iam.gserviceaccount.com"
        - role: "READER"
          specialGroup: "projectReaders"
        - role: "WRITER"
          specialGroup: "projectWriters"
      defaultTableExpirationMs: "3600000"  # 1 hour default expiration
      labels:
        environment: "collaborative"
        purpose: "data-science"
    metadata:
      dependsOn:
        - enable_bigquery_api

  # BigQuery table for customer data
  customer_data_table:
    type: gcp-types/bigquery-v2:tables
    properties:
      datasetId: $(ref.analytics_dataset.datasetId)
      projectId: $(ref.project_id.value)
      tableId: "customer_data"
      friendlyName: "Customer Master Data"
      description: "Customer information and registration details"
      schema:
        fields:
          - name: "customer_id"
            type: "STRING"
            mode: "REQUIRED"
            description: "Unique customer identifier"
          - name: "name"
            type: "STRING"
            mode: "REQUIRED"
            description: "Customer full name"
          - name: "email"
            type: "STRING"
            mode: "REQUIRED"
            description: "Customer email address"
          - name: "signup_date"
            type: "DATE"
            mode: "REQUIRED"
            description: "Customer registration date"
      labels:
        data_type: "customer"
        sensitivity: "pii"
    metadata:
      dependsOn:
        - analytics_dataset

  # BigQuery table for transaction data
  transaction_data_table:
    type: gcp-types/bigquery-v2:tables
    properties:
      datasetId: $(ref.analytics_dataset.datasetId)
      projectId: $(ref.project_id.value)
      tableId: "transaction_data"
      friendlyName: "Transaction Records"
      description: "Customer transaction history and amounts"
      schema:
        fields:
          - name: "transaction_id"
            type: "STRING"
            mode: "REQUIRED"
            description: "Unique transaction identifier"
          - name: "customer_id"
            type: "STRING"
            mode: "REQUIRED"
            description: "Associated customer identifier"
          - name: "amount"
            type: "FLOAT"
            mode: "REQUIRED"
            description: "Transaction amount in base currency"
          - name: "transaction_date"
            type: "TIMESTAMP"
            mode: "REQUIRED"
            description: "Transaction timestamp"
      labels:
        data_type: "transaction"
        sensitivity: "financial"
    metadata:
      dependsOn:
        - analytics_dataset

  # Dataform repository for data transformations
  dataform_repository:
    type: gcp-types/dataform-v1beta1:projects.locations.repositories
    properties:
      parent: projects/$(ref.project_id.value)/locations/$(ref.region.value)
      repositoryId: dataform-repo-$(ref.resource_suffix.value)
      repository:
        displayName: "Collaborative Data Science Repository"
        description: "Git repository for managing data transformations and workflows"
        gitRemoteSettings:
          url: "https://github.com/example/dataform-repo.git"  # Replace with actual repo
          defaultBranch: "main"
          authenticationTokenSecretVersion: ""  # Configure if using private repo
        labels:
          environment: "collaborative"
          team: "data-science"
    metadata:
      dependsOn:
        - enable_dataform_api

  # Dataform development workspace
  dataform_workspace:
    type: gcp-types/dataform-v1beta1:projects.locations.repositories.workspaces
    properties:
      parent: $(ref.dataform_repository.name)
      workspaceId: dev-workspace-$(ref.resource_suffix.value)
      workspace:
        displayName: "Development Workspace"
        description: "Isolated development environment for data transformations"
    metadata:
      dependsOn:
        - dataform_repository

  # Service account for Colab Enterprise runtimes
  colab_service_account:
    type: gcp-types/iam-v1:projects.serviceAccounts
    properties:
      accountId: colab-sa-$(ref.resource_suffix.value)
      serviceAccount:
        displayName: "Colab Enterprise Service Account"
        description: "Service account for Colab Enterprise notebook runtimes"
      projectId: $(ref.project_id.value)
    metadata:
      dependsOn:
        - enable_aiplatform_api

  # IAM policy binding for Colab service account - BigQuery access
  colab_sa_bigquery_binding:
    type: gcp-types/cloudresourcemanager-v1:virtual.projects.iamMemberBinding
    properties:
      resource: $(ref.project_id.value)
      role: roles/bigquery.dataEditor
      member: serviceAccount:$(ref.colab_service_account.email)
    metadata:
      dependsOn:
        - colab_service_account

  # IAM policy binding for Colab service account - Storage access
  colab_sa_storage_binding:
    type: gcp-types/cloudresourcemanager-v1:virtual.projects.iamMemberBinding
    properties:
      resource: $(ref.project_id.value)
      role: roles/storage.objectAdmin
      member: serviceAccount:$(ref.colab_service_account.email)
    metadata:
      dependsOn:
        - colab_service_account

  # IAM policy binding for Colab service account - Vertex AI access
  colab_sa_vertex_binding:
    type: gcp-types/cloudresourcemanager-v1:virtual.projects.iamMemberBinding
    properties:
      resource: $(ref.project_id.value)
      role: roles/aiplatform.user
      member: serviceAccount:$(ref.colab_service_account.email)
    metadata:
      dependsOn:
        - colab_service_account

  # Vertex AI Workbench instance for Colab Enterprise
  colab_workbench_instance:
    type: gcp-types/notebooks-v1:projects.locations.instances
    properties:
      parent: projects/$(ref.project_id.value)/locations/$(ref.zone.value)
      instanceId: colab-workbench-$(ref.resource_suffix.value)
      instance:
        name: projects/$(ref.project_id.value)/locations/$(ref.zone.value)/instances/colab-workbench-$(ref.resource_suffix.value)
        machineType: projects/$(ref.project_id.value)/zones/$(ref.zone.value)/machineTypes/n1-standard-4
        vmImage:
          project: deeplearning-platform-release
          imageFamily: common-cpu-notebooks
        serviceAccount: $(ref.colab_service_account.email)
        bootDiskType: "PD_SSD"
        bootDiskSizeGb: "100"
        dataDiskType: "PD_STANDARD"
        dataDiskSizeGb: "200"
        noRemoveDataDisk: false
        diskEncryption: "GMEK"
        metadata:
          enable-oslogin: "true"
          proxy-mode: "service_account"
          framework: "PyTorch:1.13"
          title: "Collaborative Data Science Workbench"
        labels:
          environment: "collaborative"
          purpose: "data-science"
          team: "ml-engineering"
        tags:
          - "colab-enterprise"
          - "data-science"
    metadata:
      dependsOn:
        - enable_notebooks_api
        - colab_service_account
        - colab_sa_bigquery_binding
        - colab_sa_storage_binding
        - colab_sa_vertex_binding

  # VPC network for secure connectivity (optional but recommended)
  data_science_network:
    type: gcp-types/compute-v1:networks
    properties:
      name: ds-network-$(ref.resource_suffix.value)
      description: "Network for collaborative data science workflows"
      autoCreateSubnetworks: false
      routingConfig:
        routingMode: "REGIONAL"
    metadata:
      dependsOn:
        - enable_compute_api

  # Subnet for data science resources
  data_science_subnet:
    type: gcp-types/compute-v1:subnetworks
    properties:
      name: ds-subnet-$(ref.resource_suffix.value)
      description: "Subnet for data science workloads"
      network: $(ref.data_science_network.selfLink)
      ipCidrRange: "10.0.0.0/24"
      region: $(ref.region.value)
      privateIpGoogleAccess: true
      enableFlowLogs: true
      logConfig:
        enable: true
        flowSampling: 0.5
        aggregationInterval: "INTERVAL_10_MIN"
    metadata:
      dependsOn:
        - data_science_network

  # Firewall rule for internal communication
  internal_firewall_rule:
    type: gcp-types/compute-v1:firewalls
    properties:
      name: ds-internal-$(ref.resource_suffix.value)
      description: "Allow internal communication within data science network"
      network: $(ref.data_science_network.selfLink)
      direction: "INGRESS"
      priority: 1000
      sourceRanges:
        - "10.0.0.0/24"
      allowed:
        - IPProtocol: "tcp"
          ports:
            - "22"
            - "8080"
            - "8888"
            - "9000"
      targetTags:
        - "colab-enterprise"
        - "data-science"
    metadata:
      dependsOn:
        - data_science_network

# Outputs for verification and integration
outputs:
  project_id:
    description: "Google Cloud Project ID"
    value: $(ref.project_id.value)

  data_lake_bucket_name:
    description: "Cloud Storage bucket name for data lake"
    value: $(ref.data_lake_bucket.name)

  data_lake_bucket_url:
    description: "Cloud Storage bucket URL"
    value: "gs://$(ref.data_lake_bucket.name)"

  bigquery_dataset_id:
    description: "BigQuery dataset ID for analytics"
    value: $(ref.analytics_dataset.datasetId)

  bigquery_dataset_location:
    description: "BigQuery dataset location"
    value: $(ref.analytics_dataset.location)

  customer_table_id:
    description: "Customer data table ID"
    value: "$(ref.project_id.value).$(ref.analytics_dataset.datasetId).$(ref.customer_data_table.tableId)"

  transaction_table_id:
    description: "Transaction data table ID"
    value: "$(ref.project_id.value).$(ref.analytics_dataset.datasetId).$(ref.transaction_data_table.tableId)"

  dataform_repository_name:
    description: "Dataform repository resource name"
    value: $(ref.dataform_repository.name)

  dataform_workspace_name:
    description: "Dataform workspace resource name"
    value: $(ref.dataform_workspace.name)

  colab_service_account_email:
    description: "Service account email for Colab Enterprise"
    value: $(ref.colab_service_account.email)

  workbench_instance_name:
    description: "Vertex AI Workbench instance name"
    value: $(ref.colab_workbench_instance.name)

  workbench_proxy_uri:
    description: "Vertex AI Workbench proxy URI for accessing notebooks"
    value: "https://$(ref.colab_workbench_instance.proxyUri)"

  network_name:
    description: "VPC network name for data science workflows"
    value: $(ref.data_science_network.name)

  subnet_name:
    description: "Subnet name for data science resources"
    value: $(ref.data_science_subnet.name)

  region:
    description: "Deployment region"
    value: $(ref.region.value)

  zone:
    description: "Deployment zone"
    value: $(ref.zone.value)

# Metadata for Infrastructure Manager
metadata:
  version: "1.0"
  description: "Collaborative Data Science Workflows with Colab Enterprise and Dataform"
  author: "Google Cloud Infrastructure Manager"
  created: "2025-07-12"
  labels:
    recipe: "collaborative-data-science-workflows"
    provider: "gcp"
    category: "analytics"
    difficulty: "200"