# Example Terraform variables file for AWS automated data ingestion pipelines
# Copy this file to terraform.tfvars and modify the values as needed

# ========================================
# Basic Configuration
# ========================================

# Project name for resource naming (lowercase, numbers, hyphens only)
project_name = "data-ingestion"

# Environment name (dev, staging, prod)
environment = "dev"

# AWS region for all resources
aws_region = "us-east-1"

# ========================================
# OpenSearch Domain Configuration
# ========================================

# Leave empty for auto-generated name, or specify custom name
opensearch_domain_name = ""

# OpenSearch engine version
opensearch_version = "OpenSearch_2.3"

# Instance configuration for OpenSearch cluster
opensearch_instance_type  = "t3.small.search"  # For production, consider larger instances
opensearch_instance_count = 1                   # For production, consider multiple instances

# Storage configuration
opensearch_ebs_volume_size = 20  # GB
opensearch_ebs_volume_type = "gp3"

# ========================================
# OpenSearch Ingestion Pipeline Configuration
# ========================================

# Leave empty for auto-generated name, or specify custom name
pipeline_name = ""

# Pipeline capacity in Ingestion Compute Units (ICUs)
pipeline_min_units = 1
pipeline_max_units = 4

# ========================================
# S3 Configuration
# ========================================

# Leave empty for auto-generated name, or specify custom name
data_bucket_name = ""

# Enable versioning for data protection
enable_s3_versioning = true

# Data lifecycle management (0 to disable expiration)
s3_lifecycle_expiration_days = 90

# ========================================
# Data Processing Configuration
# ========================================

# S3 prefixes for data sources that will be processed
data_source_prefixes = [
  "logs/",
  "metrics/", 
  "events/"
]

# OpenSearch index naming pattern (supports date formatting)
opensearch_index_template = "application-logs-%{yyyy.MM.dd}"

# ========================================
# EventBridge Scheduler Configuration
# ========================================

# Leave empty for auto-generated name, or specify custom name
schedule_group_name = ""

# Enable automatic pipeline scheduling
enable_pipeline_scheduling = true

# Schedule expressions (in UTC timezone)
pipeline_start_schedule = "cron(0 8 * * ? *)"   # 8 AM UTC daily
pipeline_stop_schedule  = "cron(0 18 * * ? *)"  # 6 PM UTC daily

# Timezone for schedule expressions
schedule_timezone = "UTC"

# ========================================
# Monitoring and Logging Configuration
# ========================================

# Enable CloudWatch logging for OpenSearch domain
enable_cloudwatch_logs = true

# Log types to enable for OpenSearch domain
log_types = [
  "INDEX_SLOW_LOGS",
  "SEARCH_SLOW_LOGS", 
  "ES_APPLICATION_LOGS"
]

# CloudWatch log retention period (days)
cloudwatch_log_retention_days = 14

# ========================================
# Security Configuration
# ========================================

# Fine-grained access control (leave empty to disable)
# WARNING: Store these securely, consider using AWS Secrets Manager
opensearch_master_user_name     = ""  # Example: "admin"
opensearch_master_user_password = ""  # Example: "MySecurePassword123!"

# CIDR blocks allowed to access OpenSearch domain
# WARNING: 0.0.0.0/0 allows access from anywhere - restrict in production
allowed_cidr_blocks = [
  "0.0.0.0/0"  # For production, use specific IP ranges like "10.0.0.0/8"
]

# ========================================
# Cost Optimization
# ========================================

# Enable deletion protection for critical resources
delete_protection = false  # Set to true for production

# Enable spot instances where supported (experimental)
enable_spot_instances = false

# ========================================
# Example Production Configuration
# ========================================

# For production environments, consider these settings:
#
# project_name = "analytics-prod"
# environment = "prod"
# opensearch_instance_type = "m6g.large.search"
# opensearch_instance_count = 3
# opensearch_ebs_volume_size = 100
# pipeline_min_units = 2
# pipeline_max_units = 8
# s3_lifecycle_expiration_days = 365
# cloudwatch_log_retention_days = 30
# delete_protection = true
# allowed_cidr_blocks = ["10.0.0.0/8", "172.16.0.0/12"]

# ========================================
# Example Development Configuration
# ========================================

# For development/testing environments:
#
# project_name = "analytics-dev"
# environment = "dev"
# opensearch_instance_type = "t3.small.search"
# opensearch_instance_count = 1
# opensearch_ebs_volume_size = 20
# pipeline_min_units = 1
# pipeline_max_units = 2
# s3_lifecycle_expiration_days = 30
# cloudwatch_log_retention_days = 7
# delete_protection = false