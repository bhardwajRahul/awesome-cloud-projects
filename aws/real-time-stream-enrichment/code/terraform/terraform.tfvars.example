# Example Terraform Variables Configuration
# Copy this file to terraform.tfvars and customize for your environment

# ==============================================================================
# CORE CONFIGURATION
# ==============================================================================

# AWS region where resources will be deployed
aws_region = "us-east-1"

# Project name used for resource naming and tagging
project_name = "stream-enrichment"

# Environment designation (dev, staging, prod)
environment = "dev"

# ==============================================================================
# S3 STORAGE CONFIGURATION
# ==============================================================================

# Prefix for S3 bucket name (will be combined with random suffix)
s3_bucket_prefix = "stream-enrichment-data"

# Prefix for enriched data objects in S3
s3_data_prefix = "enriched-data"

# Prefix for error data objects in S3
s3_error_prefix = "error-data"

# ==============================================================================
# KINESIS DATA STREAM CONFIGURATION
# ==============================================================================

# Kinesis Data Stream capacity mode
# Options: "ON_DEMAND" (recommended) or "PROVISIONED"
kinesis_stream_mode = "ON_DEMAND"

# Number of shards (only used if kinesis_stream_mode = "PROVISIONED")
# kinesis_shard_count = 1

# Data retention period in hours (24 hours to 1 year)
kinesis_retention_period = 24

# ==============================================================================
# LAMBDA FUNCTION CONFIGURATION
# ==============================================================================

# Memory allocation for Lambda function (128-10240 MB)
lambda_memory_size = 256

# Function timeout in seconds (1-900 seconds)
lambda_timeout = 60

# Python runtime version
lambda_runtime = "python3.11"

# ==============================================================================
# DYNAMODB CONFIGURATION
# ==============================================================================

# DynamoDB billing mode
# Options: "PAY_PER_REQUEST" (recommended) or "PROVISIONED"
dynamodb_billing_mode = "PAY_PER_REQUEST"

# Read capacity units (only used if billing_mode = "PROVISIONED")
# dynamodb_read_capacity = 5

# Write capacity units (only used if billing_mode = "PROVISIONED")  
# dynamodb_write_capacity = 5

# Enable point-in-time recovery for data protection
enable_point_in_time_recovery = true

# Populate DynamoDB with sample reference data
populate_sample_data = true

# ==============================================================================
# KINESIS DATA FIREHOSE CONFIGURATION
# ==============================================================================

# Buffer size in MB (1-128)
firehose_buffer_size = 5

# Buffer interval in seconds (60-900)
firehose_buffer_interval = 300

# Compression format for S3 delivery
# Options: "GZIP", "ZIP", "Snappy", "HADOOP_SNAPPY", "UNCOMPRESSED"
firehose_compression_format = "GZIP"

# ==============================================================================
# EVENTBRIDGE PIPES CONFIGURATION
# ==============================================================================

# Batch size for event processing (1-100)
pipes_batch_size = 10

# Maximum batching window in seconds (0-300)
pipes_maximum_batching_window_in_seconds = 5

# Starting position for reading from stream
# Options: "LATEST", "TRIM_HORIZON", "AT_TIMESTAMP"
pipes_starting_position = "LATEST"

# ==============================================================================
# MONITORING AND LOGGING CONFIGURATION
# ==============================================================================

# Enable CloudWatch Logs for Lambda function
enable_cloudwatch_logs = true

# Log retention period in days
# Valid values: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653
log_retention_days = 14

# ==============================================================================
# SECURITY CONFIGURATION
# ==============================================================================

# Enable encryption for all supported resources
enable_encryption = true

# ==============================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT ENVIRONMENTS
# ==============================================================================

# DEVELOPMENT ENVIRONMENT
# Use minimal resources for development and testing
# aws_region = "us-east-1"
# project_name = "stream-enrichment-dev"
# environment = "dev"
# kinesis_stream_mode = "ON_DEMAND"
# lambda_memory_size = 256
# dynamodb_billing_mode = "PAY_PER_REQUEST"
# firehose_buffer_size = 1
# firehose_buffer_interval = 60
# log_retention_days = 7

# STAGING ENVIRONMENT  
# Moderate resources for testing at scale
# aws_region = "us-west-2"
# project_name = "stream-enrichment-staging"
# environment = "staging"
# kinesis_stream_mode = "ON_DEMAND"
# lambda_memory_size = 512
# dynamodb_billing_mode = "PAY_PER_REQUEST"
# firehose_buffer_size = 5
# firehose_buffer_interval = 300
# log_retention_days = 30

# PRODUCTION ENVIRONMENT
# Optimized resources for production workloads
# aws_region = "us-west-2"
# project_name = "stream-enrichment-prod"
# environment = "prod"
# kinesis_stream_mode = "PROVISIONED"
# kinesis_shard_count = 5
# lambda_memory_size = 1024
# dynamodb_billing_mode = "PROVISIONED"
# dynamodb_read_capacity = 100
# dynamodb_write_capacity = 50
# firehose_buffer_size = 128
# firehose_buffer_interval = 900
# log_retention_days = 365
# enable_point_in_time_recovery = true