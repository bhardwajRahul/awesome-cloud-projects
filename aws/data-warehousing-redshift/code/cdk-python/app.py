#!/usr/bin/env python3
"""
CDK Python Application for Data Warehousing Solutions with Redshift

This application deploys a complete data warehousing solution using Amazon Redshift Serverless,
S3 for data storage, IAM roles for secure access, and sample data for testing.

Services deployed:
- Amazon Redshift Serverless (Namespace and Workgroup)
- Amazon S3 bucket for data storage
- IAM role with appropriate permissions
- Sample data files for testing

Author: Generated by AWS CDK
Version: 1.0
"""

import os
from typing import Dict, Any

import aws_cdk as cdk
from aws_cdk import (
    Stack,
    App,
    CfnOutput,
    RemovalPolicy,
    Duration,
    aws_redshiftserverless as redshift_serverless,
    aws_s3 as s3,
    aws_s3_deployment as s3deploy,
    aws_iam as iam,
    aws_logs as logs,
)
from constructs import Construct


class DataWarehousingRedshiftStack(Stack):
    """
    CDK Stack for Amazon Redshift Serverless Data Warehousing Solution
    
    This stack creates a complete data warehousing infrastructure including:
    - Redshift Serverless namespace and workgroup
    - S3 bucket for data storage with sample data
    - IAM role with appropriate permissions for Redshift to access S3
    - CloudWatch log groups for monitoring
    """

    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)

        # Generate unique suffix for resource names
        unique_suffix = self.node.try_get_context("unique_suffix") or cdk.Fn.select(
            2, cdk.Fn.split("-", cdk.Fn.select(2, cdk.Fn.split("/", self.stack_id)))
        )

        # Create S3 bucket for data storage
        self.data_bucket = self._create_data_bucket(unique_suffix)
        
        # Create IAM role for Redshift Serverless
        self.redshift_role = self._create_redshift_iam_role(unique_suffix)
        
        # Create Redshift Serverless namespace
        self.namespace = self._create_redshift_namespace(unique_suffix)
        
        # Create Redshift Serverless workgroup
        self.workgroup = self._create_redshift_workgroup(unique_suffix)
        
        # Deploy sample data to S3
        self._deploy_sample_data()
        
        # Create CloudWatch log group for monitoring
        self._create_log_group(unique_suffix)
        
        # Create stack outputs
        self._create_outputs()

    def _create_data_bucket(self, unique_suffix: str) -> s3.Bucket:
        """
        Create S3 bucket for storing data warehouse source data
        
        Args:
            unique_suffix: Unique identifier for resource naming
            
        Returns:
            S3 Bucket construct
        """
        bucket = s3.Bucket(
            self,
            "DataBucket",
            bucket_name=f"redshift-data-{unique_suffix}",
            versioning=True,
            encryption=s3.BucketEncryption.S3_MANAGED,
            block_public_access=s3.BlockPublicAccess.BLOCK_ALL,
            removal_policy=RemovalPolicy.DESTROY,
            auto_delete_objects=True,
            lifecycle_rules=[
                s3.LifecycleRule(
                    id="TransitionToIA",
                    enabled=True,
                    transitions=[
                        s3.Transition(
                            storage_class=s3.StorageClass.INFREQUENT_ACCESS,
                            transition_after=Duration.days(30)
                        ),
                        s3.Transition(
                            storage_class=s3.StorageClass.GLACIER,
                            transition_after=Duration.days(90)
                        )
                    ]
                )
            ]
        )
        
        # Add bucket tags for cost tracking and management
        cdk.Tags.of(bucket).add("Project", "DataWarehousing")
        cdk.Tags.of(bucket).add("Environment", "Demo")
        cdk.Tags.of(bucket).add("Service", "Redshift")
        
        return bucket

    def _create_redshift_iam_role(self, unique_suffix: str) -> iam.Role:
        """
        Create IAM role for Redshift Serverless with appropriate permissions
        
        Args:
            unique_suffix: Unique identifier for resource naming
            
        Returns:
            IAM Role construct
        """
        # Create IAM role with Redshift service principal
        role = iam.Role(
            self,
            "RedshiftServerlessRole",
            role_name=f"RedshiftServerlessRole-{unique_suffix}",
            assumed_by=iam.ServicePrincipal("redshift.amazonaws.com"),
            description="IAM role for Redshift Serverless to access S3 and other AWS services",
            max_session_duration=Duration.hours(12)
        )
        
        # Attach managed policy for S3 read access
        role.add_managed_policy(
            iam.ManagedPolicy.from_aws_managed_policy_name("AmazonS3ReadOnlyAccess")
        )
        
        # Add custom policy for specific S3 bucket access
        role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "s3:GetObject",
                    "s3:GetObjectVersion",
                    "s3:ListBucket",
                    "s3:GetBucketLocation"
                ],
                resources=[
                    self.data_bucket.bucket_arn,
                    f"{self.data_bucket.bucket_arn}/*"
                ]
            )
        )
        
        # Add CloudWatch logs permissions for query logging
        role.add_to_policy(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=[
                    "logs:CreateLogGroup",
                    "logs:CreateLogStream",
                    "logs:PutLogEvents",
                    "logs:DescribeLogGroups",
                    "logs:DescribeLogStreams"
                ],
                resources=[f"arn:aws:logs:{self.region}:{self.account}:*"]
            )
        )
        
        return role

    def _create_redshift_namespace(self, unique_suffix: str) -> redshift_serverless.CfnNamespace:
        """
        Create Redshift Serverless namespace (storage layer)
        
        Args:
            unique_suffix: Unique identifier for resource naming
            
        Returns:
            Redshift Serverless Namespace construct
        """
        namespace = redshift_serverless.CfnNamespace(
            self,
            "RedshiftNamespace",
            namespace_name=f"data-warehouse-ns-{unique_suffix}",
            admin_username="awsuser",
            admin_user_password="TempPassword123!",  # Note: Use AWS Secrets Manager in production
            db_name="sampledb",
            default_iam_role_arn=self.redshift_role.role_arn,
            iam_roles=[self.redshift_role.role_arn],
            kms_key_id=None,  # Use default encryption
            log_exports=["userlog", "connectionlog", "useractivitylog"],
            tags=[
                cdk.CfnTag(key="Project", value="DataWarehousing"),
                cdk.CfnTag(key="Environment", value="Demo"),
                cdk.CfnTag(key="Service", value="Redshift")
            ]
        )
        
        # Add dependency on IAM role
        namespace.add_dependency(self.redshift_role.node.default_child)
        
        return namespace

    def _create_redshift_workgroup(self, unique_suffix: str) -> redshift_serverless.CfnWorkgroup:
        """
        Create Redshift Serverless workgroup (compute layer)
        
        Args:
            unique_suffix: Unique identifier for resource naming
            
        Returns:
            Redshift Serverless Workgroup construct
        """
        workgroup = redshift_serverless.CfnWorkgroup(
            self,
            "RedshiftWorkgroup",
            workgroup_name=f"data-warehouse-wg-{unique_suffix}",
            namespace_name=self.namespace.namespace_name,
            base_capacity=128,  # RPUs (Redshift Processing Units)
            enhanced_vpc_routing=False,
            publicly_accessible=True,  # Note: Use private subnets in production
            config_parameters=[
                redshift_serverless.CfnWorkgroup.ConfigParameterProperty(
                    parameter_key="datestyle",
                    parameter_value="ISO, MDY"
                ),
                redshift_serverless.CfnWorkgroup.ConfigParameterProperty(
                    parameter_key="query_group",
                    parameter_value="default"
                )
            ],
            tags=[
                cdk.CfnTag(key="Project", value="DataWarehousing"),
                cdk.CfnTag(key="Environment", value="Demo"),
                cdk.CfnTag(key="Service", value="Redshift")
            ]
        )
        
        # Add dependency on namespace
        workgroup.add_dependency(self.namespace)
        
        return workgroup

    def _deploy_sample_data(self) -> None:
        """
        Deploy sample CSV data files to S3 bucket for testing
        """
        # Create sample sales data content
        sales_data_content = """order_id,customer_id,product_id,quantity,price,order_date
1001,501,2001,2,29.99,2024-01-15
1002,502,2002,1,49.99,2024-01-15
1003,503,2001,3,29.99,2024-01-16
1004,501,2003,1,79.99,2024-01-16
1005,504,2002,2,49.99,2024-01-17
1006,505,2001,1,29.99,2024-01-18
1007,502,2003,2,79.99,2024-01-18
1008,506,2002,3,49.99,2024-01-19
1009,503,2003,1,79.99,2024-01-19
1010,507,2001,4,29.99,2024-01-20"""

        # Create sample customer data content
        customer_data_content = """customer_id,first_name,last_name,email,city,state
501,John,Doe,john.doe@email.com,Seattle,WA
502,Jane,Smith,jane.smith@email.com,Portland,OR
503,Mike,Johnson,mike.johnson@email.com,San Francisco,CA
504,Sarah,Wilson,sarah.wilson@email.com,Los Angeles,CA
505,David,Brown,david.brown@email.com,Denver,CO
506,Lisa,Davis,lisa.davis@email.com,Phoenix,AZ
507,Robert,Miller,robert.miller@email.com,Austin,TX"""

        # Deploy sales data file
        s3deploy.BucketDeployment(
            self,
            "SalesDataDeployment",
            sources=[
                s3deploy.Source.data(
                    "data/sales_data.csv",
                    sales_data_content
                )
            ],
            destination_bucket=self.data_bucket,
            retain_on_delete=False
        )

        # Deploy customer data file
        s3deploy.BucketDeployment(
            self,
            "CustomerDataDeployment",
            sources=[
                s3deploy.Source.data(
                    "data/customer_data.csv",
                    customer_data_content
                )
            ],
            destination_bucket=self.data_bucket,
            retain_on_delete=False
        )

    def _create_log_group(self, unique_suffix: str) -> logs.LogGroup:
        """
        Create CloudWatch log group for Redshift query logging
        
        Args:
            unique_suffix: Unique identifier for resource naming
            
        Returns:
            CloudWatch LogGroup construct
        """
        log_group = logs.LogGroup(
            self,
            "RedshiftLogGroup",
            log_group_name=f"/aws/redshift/serverless/data-warehouse-{unique_suffix}",
            retention=logs.RetentionDays.ONE_MONTH,
            removal_policy=RemovalPolicy.DESTROY
        )
        
        return log_group

    def _create_outputs(self) -> None:
        """
        Create CloudFormation stack outputs for important resources
        """
        CfnOutput(
            self,
            "DataBucketName",
            value=self.data_bucket.bucket_name,
            description="S3 bucket name for data storage",
            export_name=f"{self.stack_name}-DataBucketName"
        )

        CfnOutput(
            self,
            "DataBucketArn",
            value=self.data_bucket.bucket_arn,
            description="S3 bucket ARN for data storage",
            export_name=f"{self.stack_name}-DataBucketArn"
        )

        CfnOutput(
            self,
            "RedshiftRoleArn",
            value=self.redshift_role.role_arn,
            description="IAM role ARN for Redshift Serverless",
            export_name=f"{self.stack_name}-RedshiftRoleArn"
        )

        CfnOutput(
            self,
            "RedshiftNamespaceName",
            value=self.namespace.namespace_name,
            description="Redshift Serverless namespace name",
            export_name=f"{self.stack_name}-NamespaceName"
        )

        CfnOutput(
            self,
            "RedshiftWorkgroupName", 
            value=self.workgroup.workgroup_name,
            description="Redshift Serverless workgroup name",
            export_name=f"{self.stack_name}-WorkgroupName"
        )

        CfnOutput(
            self,
            "DatabaseName",
            value="sampledb",
            description="Redshift database name",
            export_name=f"{self.stack_name}-DatabaseName"
        )

        CfnOutput(
            self,
            "AdminUsername",
            value="awsuser",
            description="Redshift admin username",
            export_name=f"{self.stack_name}-AdminUsername"
        )

        CfnOutput(
            self,
            "QueryEditorUrl",
            value=f"https://console.aws.amazon.com/redshiftv2/home?region={self.region}#query-editor",
            description="URL to Redshift Query Editor v2",
            export_name=f"{self.stack_name}-QueryEditorUrl"
        )


def main():
    """
    Main application entry point
    """
    app = App()
    
    # Get environment configuration
    env = cdk.Environment(
        account=os.getenv('CDK_DEFAULT_ACCOUNT'),
        region=os.getenv('CDK_DEFAULT_REGION')
    )
    
    # Create the data warehousing stack
    DataWarehousingRedshiftStack(
        app,
        "DataWarehousingRedshiftStack",
        env=env,
        description="CDK stack for Amazon Redshift Serverless data warehousing solution"
    )
    
    app.synth()


if __name__ == "__main__":
    main()