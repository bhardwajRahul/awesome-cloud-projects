# Example Terraform Variables for Real-time Data Quality Monitoring with Deequ on EMR
# Copy this file to terraform.tfvars and customize the values for your environment

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================

# AWS Region for resource deployment
aws_region = "us-east-1"

# Environment name for resource tagging and naming
environment = "dev"

# Project name for resource naming (lowercase, hyphens only)
project_name = "deequ-quality-monitor"

# Email address for data quality alerts (leave empty to skip email notifications)
notification_email = "your-email@company.com"

# =============================================================================
# EMR CLUSTER CONFIGURATION
# =============================================================================

# EMR release version (supports Spark 3.4+ required for Deequ 2.0+)
emr_release_label = "emr-6.15.0"

# EC2 instance type for EMR cluster nodes
# Options: m5.large, m5.xlarge, m5.2xlarge, m5.4xlarge, r5.xlarge, r5.2xlarge
emr_instance_type = "m5.xlarge"

# Total number of instances in the cluster (1 master + N-1 core instances)
emr_instance_count = 3

# Auto-termination timeout in seconds (3600 = 1 hour, 0 to disable)
emr_auto_termination_timeout = 3600

# =============================================================================
# COST OPTIMIZATION
# =============================================================================

# Use Spot instances to reduce costs (recommended for dev/test environments)
enable_spot_instances = false

# Percentage of core instances to run as Spot (when enable_spot_instances = true)
spot_instance_percentage = 50

# =============================================================================
# S3 CONFIGURATION
# =============================================================================

# Base name for S3 bucket (will be made unique with random suffix)
s3_bucket_name = "deequ-data-quality"

# Allow Terraform to destroy S3 bucket even if it contains objects
# WARNING: Set to true only for development environments
s3_force_destroy = false

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Enable encryption at rest for EMR cluster storage
enable_encryption_at_rest = true

# Enable encryption in transit for EMR cluster communication
enable_encryption_in_transit = true

# CIDR blocks allowed to access EMR cluster (adjust for your network)
allowed_cidr_blocks = ["10.0.0.0/8", "172.16.0.0/12", "192.168.0.0/16"]

# VPC ID for EMR cluster (leave empty to use default VPC)
vpc_id = ""

# Subnet ID for EMR cluster (leave empty to use default subnet)
subnet_id = ""

# =============================================================================
# MONITORING CONFIGURATION
# =============================================================================

# Create CloudWatch dashboard for data quality metrics
create_dashboard = true

# CloudWatch log retention period in days
# Options: 1, 3, 5, 7, 14, 30, 60, 90, 120, 150, 180, 365, 400, 545, 731, 1827, 3653
cloudwatch_log_retention_days = 7

# =============================================================================
# ADVANCED SPARK CONFIGURATION
# =============================================================================

# Additional Spark configurations for performance tuning
spark_configurations = {
  "spark.sql.adaptive.enabled"                        = "true"
  "spark.sql.adaptive.coalescePartitions.enabled"     = "true"
  "spark.serializer"                                   = "org.apache.spark.serializer.KryoSerializer"
  "spark.dynamicAllocation.enabled"                    = "true"
  "spark.dynamicAllocation.minExecutors"               = "1"
  "spark.dynamicAllocation.maxExecutors"               = "10"
  "spark.sql.adaptive.advisoryPartitionSizeInBytes"   = "134217728"  # 128MB
  "spark.sql.adaptive.skewJoin.enabled"               = "true"
  "spark.sql.adaptive.localShuffleReader.enabled"     = "true"
}

# =============================================================================
# DEEQU CONFIGURATION
# =============================================================================

# Deequ library version (must be compatible with EMR Spark version)
deequ_version = "2.0.4-spark-3.4"

# =============================================================================
# EXAMPLE CONFIGURATIONS FOR DIFFERENT ENVIRONMENTS
# =============================================================================

# Development Environment Example:
# environment = "dev"
# emr_instance_type = "m5.large"
# emr_instance_count = 2
# enable_spot_instances = true
# spot_instance_percentage = 80
# emr_auto_termination_timeout = 1800  # 30 minutes
# s3_force_destroy = true
# cloudwatch_log_retention_days = 3

# Staging Environment Example:
# environment = "staging"
# emr_instance_type = "m5.xlarge"
# emr_instance_count = 3
# enable_spot_instances = true
# spot_instance_percentage = 50
# emr_auto_termination_timeout = 7200  # 2 hours
# s3_force_destroy = false
# cloudwatch_log_retention_days = 7

# Production Environment Example:
# environment = "prod"
# emr_instance_type = "m5.2xlarge"
# emr_instance_count = 5
# enable_spot_instances = false
# emr_auto_termination_timeout = 0  # Disabled
# s3_force_destroy = false
# cloudwatch_log_retention_days = 30
# enable_encryption_at_rest = true
# enable_encryption_in_transit = true