AWSTemplateFormatVersion: '2010-09-09'
Description: 'GPU-Accelerated Workloads with EC2 P4 and G4 Instances - Complete infrastructure for machine learning training and inference workloads'

Parameters:
  # Environment Configuration
  Environment:
    Type: String
    Default: dev
    AllowedValues: [dev, staging, prod]
    Description: Environment name for resource tagging and configuration

  # Instance Configuration
  P4InstanceType:
    Type: String
    Default: p4d.24xlarge
    AllowedValues: 
      - p4d.24xlarge
      - p4de.24xlarge
    Description: P4 instance type for ML training workloads

  G4InstanceType:
    Type: String
    Default: g4dn.xlarge
    AllowedValues:
      - g4dn.xlarge
      - g4dn.2xlarge
      - g4dn.4xlarge
      - g4dn.8xlarge
      - g4dn.12xlarge
      - g4dn.16xlarge
    Description: G4 instance type for inference and graphics workloads

  # Spot Fleet Configuration
  EnableSpotFleet:
    Type: String
    Default: 'true'
    AllowedValues: ['true', 'false']
    Description: Enable Spot Fleet for cost optimization (requires spot fleet service role)

  SpotPrice:
    Type: String
    Default: '0.50'
    Description: Maximum price per hour for spot instances

  SpotFleetTargetCapacity:
    Type: Number
    Default: 2
    MinValue: 1
    MaxValue: 10
    Description: Target number of spot instances in the fleet

  # Network Configuration
  VpcId:
    Type: AWS::EC2::VPC::Id
    Description: VPC ID where resources will be created

  SubnetId:
    Type: AWS::EC2::Subnet::Id
    Description: Subnet ID for instance placement

  # Security Configuration
  AllowedCidr:
    Type: String
    Default: '0.0.0.0/0'
    AllowedPattern: '^(\d{1,3}\.){3}\d{1,3}/\d{1,2}$'
    Description: CIDR block allowed for SSH access (restrict for production)

  # Monitoring Configuration
  NotificationEmail:
    Type: String
    AllowedPattern: '^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    Description: Email address for CloudWatch alarm notifications

  # Cost Optimization
  EnableCostOptimization:
    Type: String
    Default: 'true'
    AllowedValues: ['true', 'false']
    Description: Enable automated cost optimization monitoring

  LowUtilizationThreshold:
    Type: Number
    Default: 10
    MinValue: 1
    MaxValue: 50
    Description: GPU utilization threshold (%) below which instances are tagged for review

Conditions:
  CreateSpotFleet: !Equals [!Ref EnableSpotFleet, 'true']
  CreateG4OnDemand: !Equals [!Ref EnableSpotFleet, 'false']
  EnableCostOptimizationCondition: !Equals [!Ref EnableCostOptimization, 'true']
  IsProdEnvironment: !Equals [!Ref Environment, 'prod']

Mappings:
  # Latest Deep Learning AMI IDs by region (update as needed)
  RegionMap:
    us-east-1:
      DLAMI: ami-0c02fb55956c7d316  # Deep Learning AMI GPU PyTorch 2.0.1 (Ubuntu 20.04)
    us-west-2:
      DLAMI: ami-0c02fb55956c7d316
    eu-west-1:
      DLAMI: ami-0c02fb55956c7d316
    ap-southeast-1:
      DLAMI: ami-0c02fb55956c7d316

Resources:
  # Security Group for GPU Instances
  GPUSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Security group for GPU workload instances
      VpcId: !Ref VpcId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: !Ref AllowedCidr
          Description: SSH access for instance management
        - IpProtocol: tcp
          FromPort: 8888
          ToPort: 8888
          SourceSecurityGroupId: !Ref 'AWS::NoValue'
          SourceSecurityGroupName: !Ref 'AWS::NoValue'
          Description: Jupyter notebook access between instances
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
          Description: All outbound traffic
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-workload-sg'
        - Key: Environment
          Value: !Ref Environment
        - Key: Purpose
          Value: GPU-Workload

  # Self-referencing security group rule for Jupyter access
  JupyterSelfReference:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref GPUSecurityGroup
      IpProtocol: tcp
      FromPort: 8888
      ToPort: 8888
      SourceSecurityGroupId: !Ref GPUSecurityGroup
      Description: Jupyter notebook access between GPU instances

  # Key Pair for SSH Access
  GPUKeyPair:
    Type: AWS::EC2::KeyPair
    Properties:
      KeyName: !Sub '${Environment}-gpu-workload-key-${AWS::StackName}'
      KeyType: rsa
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-workload-key'
        - Key: Environment
          Value: !Ref Environment

  # IAM Role for GPU Instances
  GPUInstanceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${Environment}-gpu-workload-role-${AWS::StackName}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: ec2.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy
      Policies:
        - PolicyName: GPUCustomMetricsPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - cloudwatch:PutMetricData
                  - cloudwatch:ListMetrics
                  - ec2:DescribeInstances
                  - ec2:DescribeTags
                  - ec2:CreateTags
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:DeleteObject
                Resource: !Sub '${GPUS3Bucket}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource: !Ref GPUS3Bucket
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-workload-role'
        - Key: Environment
          Value: !Ref Environment

  # Instance Profile for GPU Instances
  GPUInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: !Sub '${Environment}-gpu-workload-profile-${AWS::StackName}'
      Roles:
        - !Ref GPUInstanceRole

  # S3 Bucket for training data and model artifacts
  GPUS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${Environment}-gpu-workload-data-${AWS::AccountId}-${AWS::Region}'
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteIncompleteMultipartUploads
            Status: Enabled
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 7
          - Id: TransitionToIA
            Status: Enabled
            Transition:
              StorageClass: STANDARD_IA
              TransitionInDays: 30
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-workload-data'
        - Key: Environment
          Value: !Ref Environment

  # SNS Topic for monitoring alerts
  GPUAlertsTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub '${Environment}-gpu-workload-alerts-${AWS::StackName}'
      DisplayName: GPU Workload Monitoring Alerts
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-workload-alerts'
        - Key: Environment
          Value: !Ref Environment

  # SNS Subscription for email notifications
  GPUAlertsSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      TopicArn: !Ref GPUAlertsTopic
      Protocol: email
      Endpoint: !Ref NotificationEmail

  # User Data Script for GPU setup (Base64 encoded)
  GPUUserDataScript:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Sub '/${Environment}/gpu-workload/userdata'
      Type: String
      Value: !Sub |
        #!/bin/bash
        yum update -y
        yum install -y awscli

        # Install NVIDIA drivers
        aws s3 cp --recursive s3://ec2-linux-nvidia-drivers/latest/ .
        chmod +x NVIDIA-Linux-x86_64*.run
        ./NVIDIA-Linux-x86_64*.run --silent

        # Install Docker for containerized workloads
        yum install -y docker
        systemctl start docker
        systemctl enable docker
        usermod -aG docker ec2-user

        # Install NVIDIA Container Toolkit
        distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
        curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | rpm --import -
        curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | tee /etc/yum.repos.d/nvidia-docker.repo
        yum install -y nvidia-docker2
        systemctl restart docker

        # Install Python and ML frameworks
        amazon-linux-extras install python3.8 -y
        pip3 install torch torchvision torchaudio tensorflow-gpu jupyter matplotlib pandas numpy

        # Install CloudWatch agent
        wget https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
        rpm -U ./amazon-cloudwatch-agent.rpm

        # Configure GPU monitoring
        cat > /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json << 'EOF'
        {
            "agent": {
                "metrics_collection_interval": 60
            },
            "metrics": {
                "namespace": "GPU/EC2",
                "metrics_collected": {
                    "nvidia_gpu": {
                        "measurement": [
                            "utilization_gpu",
                            "utilization_memory",
                            "temperature_gpu",
                            "power_draw"
                        ],
                        "metrics_collection_interval": 60
                    }
                }
            }
        }
        EOF

        # Start CloudWatch agent
        /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json -s

        # Create GPU monitoring script
        cat > /home/ec2-user/monitor-gpu.py << 'EOF'
        #!/usr/bin/env python3
        import subprocess
        import json
        import time
        import boto3
        from datetime import datetime

        def get_gpu_metrics():
            try:
                result = subprocess.run([
                    'nvidia-smi', 
                    '--query-gpu=utilization.gpu,utilization.memory,temperature.gpu,power.draw',
                    '--format=csv,noheader,nounits'
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    metrics = result.stdout.strip().split(', ')
                    return {
                        'gpu_util': float(metrics[0]),
                        'mem_util': float(metrics[1]),
                        'temperature': float(metrics[2]),
                        'power_draw': float(metrics[3])
                    }
            except Exception as e:
                print(f"Error getting GPU metrics: {e}")
            return None

        def send_custom_metrics(metrics, instance_id):
            cloudwatch = boto3.client('cloudwatch')
            
            try:
                cloudwatch.put_metric_data(
                    Namespace='GPU/Custom',
                    MetricData=[
                        {
                            'MetricName': 'GPUUtilization',
                            'Value': metrics['gpu_util'],
                            'Unit': 'Percent',
                            'Dimensions': [
                                {'Name': 'InstanceId', 'Value': instance_id}
                            ]
                        },
                        {
                            'MetricName': 'GPUMemoryUtilization',
                            'Value': metrics['mem_util'],
                            'Unit': 'Percent',
                            'Dimensions': [
                                {'Name': 'InstanceId', 'Value': instance_id}
                            ]
                        },
                        {
                            'MetricName': 'GPUTemperature',
                            'Value': metrics['temperature'],
                            'Unit': 'None',
                            'Dimensions': [
                                {'Name': 'InstanceId', 'Value': instance_id}
                            ]
                        },
                        {
                            'MetricName': 'GPUPowerDraw',
                            'Value': metrics['power_draw'],
                            'Unit': 'None',
                            'Dimensions': [
                                {'Name': 'InstanceId', 'Value': instance_id}
                            ]
                        }
                    ]
                )
                print(f"Metrics sent: {metrics}")
            except Exception as e:
                print(f"Error sending metrics: {e}")

        if __name__ == "__main__":
            try:
                result = subprocess.run([
                    'curl', '-s', 
                    'http://169.254.169.254/latest/meta-data/instance-id'
                ], capture_output=True, text=True)
                instance_id = result.stdout.strip()
            except:
                instance_id = "unknown"
            
            while True:
                metrics = get_gpu_metrics()
                if metrics:
                    send_custom_metrics(metrics, instance_id)
                    print(f"{datetime.now()}: {metrics}")
                time.sleep(60)
        EOF

        chmod +x /home/ec2-user/monitor-gpu.py
        chown ec2-user:ec2-user /home/ec2-user/monitor-gpu.py

        echo "GPU setup completed" > /tmp/gpu-setup-complete
      Description: User data script for GPU instance setup
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-userdata'
        - Key: Environment
          Value: !Ref Environment

  # P4 Instance for ML Training
  P4TrainingInstance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', DLAMI]
      InstanceType: !Ref P4InstanceType
      KeyName: !Ref GPUKeyPair
      SecurityGroupIds:
        - !Ref GPUSecurityGroup
      SubnetId: !Ref SubnetId
      IamInstanceProfile: !Ref GPUInstanceProfile
      UserData: 
        Fn::Base64: !GetAtt GPUUserDataScript.Value
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeType: gp3
            VolumeSize: 500
            Iops: 3000
            Throughput: 125
            Encrypted: true
            DeleteOnTermination: true
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-P4-ML-Training'
        - Key: Environment
          Value: !Ref Environment
        - Key: Purpose
          Value: GPU-Workload
        - Key: InstanceType
          Value: Training
        - Key: GPUType
          Value: A100

  # Spot Fleet for G4 Instances (conditional)
  G4SpotFleet:
    Type: AWS::EC2::SpotFleet
    Condition: CreateSpotFleet
    Properties:
      SpotFleetRequestConfigData:
        SpotPrice: !Ref SpotPrice
        TargetCapacity: !Ref SpotFleetTargetCapacity
        AllocationStrategy: lowestPrice
        IamFleetRole: !Sub 'arn:aws:iam::${AWS::AccountId}:role/aws-ec2-spot-fleet-tagging-role'
        LaunchSpecifications:
          - ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', DLAMI]
            InstanceType: !Ref G4InstanceType
            KeyName: !Ref GPUKeyPair
            SecurityGroups:
              - GroupId: !Ref GPUSecurityGroup
            SubnetId: !Ref SubnetId
            IamInstanceProfile:
              Name: !Ref GPUInstanceProfile
            UserData: 
              Fn::Base64: !GetAtt GPUUserDataScript.Value
            BlockDeviceMappings:
              - DeviceName: /dev/sda1
                Ebs:
                  VolumeType: gp3
                  VolumeSize: 200
                  Iops: 3000
                  Throughput: 125
                  Encrypted: true
                  DeleteOnTermination: true
            TagSpecifications:
              - ResourceType: instance
                Tags:
                  - Key: Name
                    Value: !Sub '${Environment}-G4-Spot-Inference'
                  - Key: Environment
                    Value: !Ref Environment
                  - Key: Purpose
                    Value: GPU-Workload
                  - Key: InstanceType
                    Value: Inference
                  - Key: GPUType
                    Value: T4

  # G4 On-Demand Instance (alternative to Spot Fleet)
  G4OnDemandInstance:
    Type: AWS::EC2::Instance
    Condition: CreateG4OnDemand
    Properties:
      ImageId: !FindInMap [RegionMap, !Ref 'AWS::Region', DLAMI]
      InstanceType: !Ref G4InstanceType
      KeyName: !Ref GPUKeyPair
      SecurityGroupIds:
        - !Ref GPUSecurityGroup
      SubnetId: !Ref SubnetId
      IamInstanceProfile: !Ref GPUInstanceProfile
      UserData: 
        Fn::Base64: !GetAtt GPUUserDataScript.Value
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeType: gp3
            VolumeSize: 200
            Iops: 3000
            Throughput: 125
            Encrypted: true
            DeleteOnTermination: true
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-G4-Inference'
        - Key: Environment
          Value: !Ref Environment
        - Key: Purpose
          Value: GPU-Workload
        - Key: InstanceType
          Value: Inference
        - Key: GPUType
          Value: T4

  # CloudWatch Dashboard for GPU Monitoring
  GPUMonitoringDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub '${Environment}-GPU-Workload-Monitoring'
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0, "y": 0, "width": 12, "height": 6,
              "properties": {
                "metrics": [
                  [ "GPU/EC2", "utilization_gpu", "InstanceId", "${P4TrainingInstance}" ]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "P4 GPU Utilization",
                "yAxis": {
                  "left": {
                    "min": 0,
                    "max": 100
                  }
                }
              }
            },
            {
              "type": "metric",
              "x": 12, "y": 0, "width": 12, "height": 6,
              "properties": {
                "metrics": [
                  [ "GPU/EC2", "utilization_memory", "InstanceId", "${P4TrainingInstance}" ]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "P4 GPU Memory Utilization",
                "yAxis": {
                  "left": {
                    "min": 0,
                    "max": 100
                  }
                }
              }
            },
            {
              "type": "metric",
              "x": 0, "y": 6, "width": 12, "height": 6,
              "properties": {
                "metrics": [
                  [ "GPU/EC2", "temperature_gpu", "InstanceId", "${P4TrainingInstance}" ]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "P4 GPU Temperature",
                "yAxis": {
                  "left": {
                    "min": 30,
                    "max": 90
                  }
                }
              }
            },
            {
              "type": "metric",
              "x": 12, "y": 6, "width": 12, "height": 6,
              "properties": {
                "metrics": [
                  [ "GPU/EC2", "power_draw", "InstanceId", "${P4TrainingInstance}" ]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "P4 GPU Power Consumption"
              }
            }
          ]
        }

  # CloudWatch Alarms for GPU Monitoring
  GPUHighTemperatureAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${Environment}-GPU-High-Temperature-${P4TrainingInstance}'
      AlarmDescription: P4 GPU temperature too high
      MetricName: temperature_gpu
      Namespace: GPU/EC2
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: 85
      ComparisonOperator: GreaterThanThreshold
      AlarmActions:
        - !Ref GPUAlertsTopic
      Dimensions:
        - Name: InstanceId
          Value: !Ref P4TrainingInstance
      TreatMissingData: notBreaching
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-GPU-High-Temperature'
        - Key: Environment
          Value: !Ref Environment

  GPULowUtilizationAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${Environment}-GPU-Low-Utilization-${P4TrainingInstance}'
      AlarmDescription: P4 GPU utilization too low - consider stopping for cost optimization
      MetricName: utilization_gpu
      Namespace: GPU/EC2
      Statistic: Average
      Period: 1800
      EvaluationPeriods: 3
      Threshold: !Ref LowUtilizationThreshold
      ComparisonOperator: LessThanThreshold
      AlarmActions:
        - !Ref GPUAlertsTopic
      Dimensions:
        - Name: InstanceId
          Value: !Ref P4TrainingInstance
      TreatMissingData: notBreaching
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-GPU-Low-Utilization'
        - Key: Environment
          Value: !Ref Environment

  # Lambda Function for Cost Optimization (conditional)
  CostOptimizationLambdaRole:
    Type: AWS::IAM::Role
    Condition: EnableCostOptimizationCondition
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: CostOptimizationPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ec2:DescribeInstances
                  - ec2:CreateTags
                  - cloudwatch:GetMetricStatistics
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'

  CostOptimizationLambda:
    Type: AWS::Lambda::Function
    Condition: EnableCostOptimizationCondition
    Properties:
      FunctionName: !Sub '${Environment}-gpu-cost-optimizer'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt CostOptimizationLambdaRole.Arn
      Timeout: 300
      Code:
        ZipFile: !Sub |
          import boto3
          import json
          from datetime import datetime, timedelta
          
          def lambda_handler(event, context):
              ec2 = boto3.client('ec2')
              cloudwatch = boto3.client('cloudwatch')
              
              # Get GPU instances
              instances = ec2.describe_instances(
                  Filters=[
                      {'Name': 'tag:Purpose', 'Values': ['GPU-Workload']},
                      {'Name': 'instance-state-name', 'Values': ['running']}
                  ]
              )
              
              for reservation in instances['Reservations']:
                  for instance in reservation['Instances']:
                      instance_id = instance['InstanceId']
                      
                      # Check GPU utilization over last hour
                      end_time = datetime.utcnow()
                      start_time = end_time - timedelta(hours=1)
                      
                      try:
                          metrics = cloudwatch.get_metric_statistics(
                              Namespace='GPU/EC2',
                              MetricName='utilization_gpu',
                              Dimensions=[
                                  {'Name': 'InstanceId', 'Value': instance_id}
                              ],
                              StartTime=start_time,
                              EndTime=end_time,
                              Period=300,
                              Statistics=['Average']
                          )
                          
                          if metrics['Datapoints']:
                              avg_util = sum(dp['Average'] for dp in metrics['Datapoints']) / len(metrics['Datapoints'])
                              
                              # If utilization < threshold for an hour, consider stopping
                              if avg_util < ${LowUtilizationThreshold}:
                                  print(f"Low utilization detected for {instance_id}: {avg_util}%. Consider stopping.")
                                  
                                  # Add tag for review
                                  ec2.create_tags(
                                      Resources=[instance_id],
                                      Tags=[
                                          {'Key': 'LowUtilization', 'Value': str(datetime.now())},
                                          {'Key': 'ReviewForTermination', 'Value': 'true'}
                                      ]
                                  )
                              
                      except Exception as e:
                          print(f"Error checking metrics for {instance_id}: {e}")
              
              return {
                  'statusCode': 200,
                  'body': json.dumps('Cost optimization check completed')
              }
      Tags:
        - Key: Name
          Value: !Sub '${Environment}-gpu-cost-optimizer'
        - Key: Environment
          Value: !Ref Environment

  # EventBridge Rule for Cost Optimization (runs every hour)
  CostOptimizationSchedule:
    Type: AWS::Events::Rule
    Condition: EnableCostOptimizationCondition
    Properties:
      Name: !Sub '${Environment}-gpu-cost-optimization-schedule'
      Description: Hourly cost optimization check for GPU instances
      ScheduleExpression: 'rate(1 hour)'
      State: ENABLED
      Targets:
        - Arn: !GetAtt CostOptimizationLambda.Arn
          Id: CostOptimizationTarget

  # Permission for EventBridge to invoke Lambda
  CostOptimizationLambdaPermission:
    Type: AWS::Lambda::Permission
    Condition: EnableCostOptimizationCondition
    Properties:
      FunctionName: !Ref CostOptimizationLambda
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt CostOptimizationSchedule.Arn

Outputs:
  # Instance Information
  P4InstanceId:
    Description: Instance ID of the P4 training instance
    Value: !Ref P4TrainingInstance
    Export:
      Name: !Sub '${AWS::StackName}-P4InstanceId'

  P4PublicIP:
    Description: Public IP address of the P4 training instance
    Value: !GetAtt P4TrainingInstance.PublicIp
    Export:
      Name: !Sub '${AWS::StackName}-P4PublicIP'

  P4PrivateIP:
    Description: Private IP address of the P4 training instance
    Value: !GetAtt P4TrainingInstance.PrivateIp
    Export:
      Name: !Sub '${AWS::StackName}-P4PrivateIP'

  G4SpotFleetId:
    Description: Spot Fleet Request ID for G4 instances
    Value: !If [CreateSpotFleet, !Ref G4SpotFleet, 'N/A - Using On-Demand']
    Export:
      Name: !Sub '${AWS::StackName}-G4SpotFleetId'

  G4OnDemandInstanceId:
    Description: Instance ID of the G4 on-demand instance
    Value: !If [CreateG4OnDemand, !Ref G4OnDemandInstance, 'N/A - Using Spot Fleet']
    Export:
      Name: !Sub '${AWS::StackName}-G4InstanceId'

  # Security and Access
  KeyPairName:
    Description: Name of the created key pair for SSH access
    Value: !Ref GPUKeyPair
    Export:
      Name: !Sub '${AWS::StackName}-KeyPairName'

  SecurityGroupId:
    Description: Security group ID for GPU instances
    Value: !Ref GPUSecurityGroup
    Export:
      Name: !Sub '${AWS::StackName}-SecurityGroupId'

  # Storage and Data
  S3BucketName:
    Description: S3 bucket for training data and model artifacts
    Value: !Ref GPUS3Bucket
    Export:
      Name: !Sub '${AWS::StackName}-S3Bucket'

  # Monitoring and Alerts
  SNSTopicArn:
    Description: SNS topic ARN for GPU monitoring alerts
    Value: !Ref GPUAlertsTopic
    Export:
      Name: !Sub '${AWS::StackName}-SNSTopicArn'

  CloudWatchDashboardURL:
    Description: URL to the CloudWatch dashboard for GPU monitoring
    Value: !Sub 'https://${AWS::Region}.console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#dashboards:name=${Environment}-GPU-Workload-Monitoring'
    Export:
      Name: !Sub '${AWS::StackName}-DashboardURL'

  # Connection Commands
  SSHCommandP4:
    Description: SSH command to connect to the P4 instance
    Value: !Sub 'ssh -i ${GPUKeyPair}.pem ubuntu@${P4TrainingInstance.PublicIp}'

  SSHCommandG4:
    Description: SSH command to connect to the G4 instance (if on-demand)
    Value: !If 
      - CreateG4OnDemand
      - !Sub 'ssh -i ${GPUKeyPair}.pem ubuntu@${G4OnDemandInstance.PublicIp}'
      - 'Check EC2 console for G4 Spot instance IPs'

  # Cost Optimization
  CostOptimizationStatus:
    Description: Status of cost optimization automation
    Value: !If [EnableCostOptimizationCondition, 'Enabled', 'Disabled']

  # Estimated Costs
  EstimatedHourlyCost:
    Description: Estimated hourly cost for running instances (approximate)
    Value: !Sub 
      - '${P4Cost} (P4) + ${G4Cost} (G4) USD/hour'
      - P4Cost: !If [IsProdEnvironment, '$32.77', '$32.77']
        G4Cost: !If [CreateSpotFleet, '$0.50-2.00', '$1.20']

  # Quick Start Guide
  QuickStartGuide:
    Description: Quick start instructions
    Value: !Sub |
      1. Download private key from EC2 console (Key Pairs section)
      2. SSH to P4: ssh -i ${GPUKeyPair}.pem ubuntu@${P4TrainingInstance.PublicIp}
      3. Check GPU: nvidia-smi
      4. Monitor: ${AWS::Region}.console.aws.amazon.com/cloudwatch/home#dashboards:name=${Environment}-GPU-Workload-Monitoring
      5. Data bucket: s3://${GPUS3Bucket}