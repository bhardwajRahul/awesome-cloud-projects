#!/bin/bash

# AWS EKS Ingress Controllers with AWS Load Balancer Controller - Deployment Script
# This script deploys a complete EKS ingress solution with AWS Load Balancer Controller
# Author: Generated by Claude Code for AWS Recipe
# Version: 1.0

set -euo pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging functions
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Error handler
error_handler() {
    local line_no=$1
    log_error "Script failed at line $line_no"
    log_error "Deployment incomplete. You may need to run cleanup manually."
    exit 1
}

trap 'error_handler $LINENO' ERR

# Configuration
CLUSTER_NAME_PREFIX="eks-ingress-demo"
NAMESPACE="ingress-demo"
DOMAIN_SUFFIX="example.com"
IAM_POLICY_NAME="AWSLoadBalancerControllerIAMPolicy"
SERVICE_ACCOUNT_NAME="aws-load-balancer-controller"
HELM_RELEASE_NAME="aws-load-balancer-controller"

# Help function
show_help() {
    cat << EOF
AWS EKS Ingress Controllers Deployment Script

USAGE:
    $0 [OPTIONS]

OPTIONS:
    -c, --cluster-name NAME     Specify EKS cluster name (default: auto-generated)
    -r, --region REGION         AWS region (default: from AWS CLI config)
    -n, --namespace NAME        Kubernetes namespace (default: $NAMESPACE)
    -d, --domain DOMAIN         Domain suffix for ingress (default: $DOMAIN_SUFFIX)
    --skip-cluster-creation     Skip EKS cluster creation (use existing cluster)
    --dry-run                   Show what would be deployed without making changes
    -h, --help                  Show this help message

EXAMPLES:
    $0                                          # Deploy with defaults
    $0 -c my-cluster -r us-west-2             # Specify cluster name and region
    $0 --skip-cluster-creation                 # Use existing cluster
    $0 --dry-run                               # Preview deployment

PREREQUISITES:
    - AWS CLI configured with appropriate permissions
    - kubectl installed
    - helm installed
    - eksctl installed (for cluster creation)
    - jq installed (for JSON parsing)

EOF
}

# Parse command line arguments
SKIP_CLUSTER_CREATION=false
DRY_RUN=false
CUSTOM_CLUSTER_NAME=""
CUSTOM_REGION=""
CUSTOM_NAMESPACE=""
CUSTOM_DOMAIN=""

while [[ $# -gt 0 ]]; do
    case $1 in
        -c|--cluster-name)
            CUSTOM_CLUSTER_NAME="$2"
            shift 2
            ;;
        -r|--region)
            CUSTOM_REGION="$2"
            shift 2
            ;;
        -n|--namespace)
            CUSTOM_NAMESPACE="$2"
            shift 2
            ;;
        -d|--domain)
            CUSTOM_DOMAIN="$2"
            shift 2
            ;;
        --skip-cluster-creation)
            SKIP_CLUSTER_CREATION=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            log_error "Unknown option: $1"
            show_help
            exit 1
            ;;
    esac
done

# Set final configuration
AWS_REGION="${CUSTOM_REGION:-$(aws configure get region)}"
NAMESPACE="${CUSTOM_NAMESPACE:-$NAMESPACE}"
DOMAIN_SUFFIX="${CUSTOM_DOMAIN:-$DOMAIN_SUFFIX}"

# Generate unique identifiers
RANDOM_SUFFIX=$(aws secretsmanager get-random-password \
    --exclude-punctuation --exclude-uppercase \
    --password-length 6 --require-each-included-type \
    --output text --query RandomPassword 2>/dev/null || echo "$(date +%s | tail -c 6)")

CLUSTER_NAME="${CUSTOM_CLUSTER_NAME:-${CLUSTER_NAME_PREFIX}-${RANDOM_SUFFIX}}"
DOMAIN_NAME="demo-${RANDOM_SUFFIX}.${DOMAIN_SUFFIX}"

# Prerequisites check
check_prerequisites() {
    log_info "Checking prerequisites..."
    
    local missing_tools=()
    
    # Check required tools
    for tool in aws kubectl helm jq; do
        if ! command -v "$tool" &> /dev/null; then
            missing_tools+=("$tool")
        fi
    done
    
    if [ "$SKIP_CLUSTER_CREATION" = false ]; then
        if ! command -v eksctl &> /dev/null; then
            missing_tools+=("eksctl")
        fi
    fi
    
    if [ ${#missing_tools[@]} -ne 0 ]; then
        log_error "Missing required tools: ${missing_tools[*]}"
        log_error "Please install missing tools and try again"
        exit 1
    fi
    
    # Check AWS CLI configuration
    if ! aws sts get-caller-identity &> /dev/null; then
        log_error "AWS CLI not configured or invalid credentials"
        exit 1
    fi
    
    # Get AWS account ID
    AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
    
    # Check AWS region
    if [ -z "$AWS_REGION" ]; then
        log_error "AWS region not configured. Set region with: aws configure set region <region>"
        exit 1
    fi
    
    log_success "Prerequisites check passed"
    log_info "AWS Account ID: $AWS_ACCOUNT_ID"
    log_info "AWS Region: $AWS_REGION"
    log_info "Cluster Name: $CLUSTER_NAME"
    log_info "Namespace: $NAMESPACE"
    log_info "Domain: $DOMAIN_NAME"
}

# Dry run summary
show_dry_run() {
    cat << EOF

${BLUE}=== DRY RUN MODE ===${NC}
The following resources would be created:

${YELLOW}EKS Cluster:${NC}
  - Name: $CLUSTER_NAME
  - Region: $AWS_REGION
  - Node Type: t3.medium
  - Node Count: 3

${YELLOW}IAM Resources:${NC}
  - Policy: $IAM_POLICY_NAME
  - Service Account: $SERVICE_ACCOUNT_NAME
  - OIDC Identity Provider

${YELLOW}Kubernetes Resources:${NC}
  - Namespace: $NAMESPACE
  - AWS Load Balancer Controller (Helm)
  - Sample applications (nginx)
  - Multiple ingress configurations (ALB, NLB)

${YELLOW}AWS Resources:${NC}
  - Application Load Balancers (multiple)
  - Network Load Balancer
  - Target Groups
  - Security Groups
  - S3 Bucket for access logs

${YELLOW}Estimated Cost:${NC} \$100-200/month

To proceed with actual deployment, run without --dry-run flag.

EOF
}

# Create or verify EKS cluster
setup_cluster() {
    if [ "$SKIP_CLUSTER_CREATION" = true ]; then
        log_info "Skipping cluster creation - using existing cluster: $CLUSTER_NAME"
        
        # Verify cluster exists
        if ! aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" &> /dev/null; then
            log_error "Cluster $CLUSTER_NAME not found in region $AWS_REGION"
            exit 1
        fi
        
        # Update kubeconfig
        aws eks update-kubeconfig --region "$AWS_REGION" --name "$CLUSTER_NAME"
        
        # Verify connectivity
        if ! kubectl get nodes &> /dev/null; then
            log_error "Cannot connect to cluster $CLUSTER_NAME"
            exit 1
        fi
        
        log_success "Connected to existing cluster: $CLUSTER_NAME"
    else
        log_info "Creating EKS cluster: $CLUSTER_NAME"
        
        # Check if cluster already exists
        if aws eks describe-cluster --name "$CLUSTER_NAME" --region "$AWS_REGION" &> /dev/null; then
            log_warning "Cluster $CLUSTER_NAME already exists, skipping creation"
        else
            eksctl create cluster \
                --name "$CLUSTER_NAME" \
                --region "$AWS_REGION" \
                --nodes 3 \
                --node-type t3.medium \
                --managed \
                --version 1.28
        fi
        
        # Update kubeconfig
        aws eks update-kubeconfig --region "$AWS_REGION" --name "$CLUSTER_NAME"
        
        log_success "EKS cluster ready: $CLUSTER_NAME"
    fi
    
    # Verify cluster connectivity
    kubectl get nodes
}

# Setup IAM for AWS Load Balancer Controller
setup_iam() {
    log_info "Setting up IAM for AWS Load Balancer Controller..."
    
    # Create IAM OIDC identity provider
    log_info "Creating OIDC identity provider..."
    if ! eksctl utils associate-iam-oidc-provider \
        --region "$AWS_REGION" \
        --cluster "$CLUSTER_NAME" \
        --approve; then
        log_warning "OIDC provider may already exist, continuing..."
    fi
    
    # Download IAM policy if not exists
    if [ ! -f "iam-policy.json" ]; then
        log_info "Downloading IAM policy document..."
        curl -sSL -o iam-policy.json \
            https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.7.2/docs/install/iam_policy.json
    fi
    
    # Create IAM policy (idempotent)
    log_info "Creating IAM policy..."
    POLICY_ARN=$(aws iam create-policy \
        --policy-name "$IAM_POLICY_NAME" \
        --policy-document file://iam-policy.json \
        --query 'Policy.Arn' --output text 2>/dev/null || \
        aws iam list-policies --query "Policies[?PolicyName=='$IAM_POLICY_NAME'].Arn" --output text)
    
    if [ -z "$POLICY_ARN" ]; then
        log_error "Failed to create or find IAM policy"
        exit 1
    fi
    
    log_success "IAM policy ready: $POLICY_ARN"
    
    # Create service account with IAM role
    log_info "Creating service account with IAM role..."
    if ! eksctl create iamserviceaccount \
        --cluster="$CLUSTER_NAME" \
        --namespace=kube-system \
        --name="$SERVICE_ACCOUNT_NAME" \
        --role-name="AmazonEKSLoadBalancerControllerRole-$CLUSTER_NAME" \
        --attach-policy-arn="$POLICY_ARN" \
        --approve; then
        log_warning "Service account may already exist, continuing..."
    fi
    
    log_success "IAM setup completed"
}

# Install AWS Load Balancer Controller
install_controller() {
    log_info "Installing AWS Load Balancer Controller..."
    
    # Add EKS Helm repository
    helm repo add eks https://aws.github.io/eks-charts
    helm repo update
    
    # Get VPC ID
    VPC_ID=$(aws eks describe-cluster --name "$CLUSTER_NAME" \
        --query 'cluster.resourcesVpcConfig.vpcId' --output text)
    
    # Install or upgrade controller
    log_info "Installing/upgrading controller via Helm..."
    helm upgrade --install "$HELM_RELEASE_NAME" eks/aws-load-balancer-controller \
        -n kube-system \
        --set clusterName="$CLUSTER_NAME" \
        --set serviceAccount.create=false \
        --set serviceAccount.name="$SERVICE_ACCOUNT_NAME" \
        --set region="$AWS_REGION" \
        --set vpcId="$VPC_ID"
    
    # Wait for controller to be ready
    log_info "Waiting for controller to be ready..."
    kubectl wait --for=condition=ready pod \
        -l app.kubernetes.io/name=aws-load-balancer-controller \
        -n kube-system --timeout=300s
    
    log_success "AWS Load Balancer Controller installed successfully"
}

# Create namespace and sample applications
deploy_applications() {
    log_info "Deploying sample applications..."
    
    # Create namespace
    kubectl create namespace "$NAMESPACE" --dry-run=client -o yaml | kubectl apply -f -
    
    # Deploy sample application v1
    kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: $NAMESPACE
  name: sample-app-v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: sample-app
      version: v1
  template:
    metadata:
      labels:
        app: sample-app
        version: v1
    spec:
      containers:
      - name: app
        image: nginx:1.21
        ports:
        - containerPort: 80
        env:
        - name: VERSION
          value: "v1"
---
apiVersion: v1
kind: Service
metadata:
  namespace: $NAMESPACE
  name: sample-app-v1
spec:
  selector:
    app: sample-app
    version: v1
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
EOF
    
    # Deploy sample application v2
    kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: $NAMESPACE
  name: sample-app-v2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: sample-app
      version: v2
  template:
    metadata:
      labels:
        app: sample-app
        version: v2
    spec:
      containers:
      - name: app
        image: nginx:1.21
        ports:
        - containerPort: 80
        env:
        - name: VERSION
          value: "v2"
---
apiVersion: v1
kind: Service
metadata:
  namespace: $NAMESPACE
  name: sample-app-v2
spec:
  selector:
    app: sample-app
    version: v2
  ports:
  - port: 80
    targetPort: 80
  type: ClusterIP
EOF
    
    # Wait for deployments to be ready
    kubectl wait --for=condition=available deployment/sample-app-v1 -n "$NAMESPACE" --timeout=300s
    kubectl wait --for=condition=available deployment/sample-app-v2 -n "$NAMESPACE" --timeout=300s
    
    log_success "Sample applications deployed successfully"
}

# Create ingress resources
deploy_ingress() {
    log_info "Deploying ingress resources..."
    
    # Basic ALB ingress
    kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  namespace: $NAMESPACE
  name: sample-app-basic-alb
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/healthcheck-path: /
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: '10'
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: '5'
    alb.ingress.kubernetes.io/healthy-threshold-count: '2'
    alb.ingress.kubernetes.io/unhealthy-threshold-count: '3'
    alb.ingress.kubernetes.io/tags: Environment=demo,Team=platform
spec:
  ingressClassName: alb
  rules:
  - host: basic.$DOMAIN_NAME
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: sample-app-v1
            port:
              number: 80
EOF
    
    # Weighted routing ingress
    kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  namespace: $NAMESPACE
  name: sample-app-weighted-routing
  annotations:
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/group.name: weighted-routing
    alb.ingress.kubernetes.io/actions.weighted-routing: |
      {
        "type": "forward",
        "forwardConfig": {
          "targetGroups": [
            {
              "serviceName": "sample-app-v1",
              "servicePort": "80",
              "weight": 70
            },
            {
              "serviceName": "sample-app-v2",
              "servicePort": "80",
              "weight": 30
            }
          ]
        }
      }
spec:
  ingressClassName: alb
  rules:
  - host: weighted.$DOMAIN_NAME
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: weighted-routing
            port:
              name: use-annotation
EOF
    
    # NLB service
    kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  namespace: $NAMESPACE
  name: sample-app-nlb
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp
    service.beta.kubernetes.io/aws-load-balancer-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-attributes: load_balancing.cross_zone.enabled=true
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-protocol: HTTP
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: /
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval: '10'
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout: '5'
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-healthy-threshold: '2'
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-unhealthy-threshold: '3'
spec:
  selector:
    app: sample-app
    version: v1
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
  type: LoadBalancer
EOF
    
    log_info "Waiting for load balancers to be created (this may take 2-3 minutes)..."
    sleep 30
    
    log_success "Ingress resources deployed successfully"
}

# Verify deployment
verify_deployment() {
    log_info "Verifying deployment..."
    
    # Check controller status
    kubectl get deployment -n kube-system aws-load-balancer-controller
    
    # Check ingress status
    kubectl get ingress -n "$NAMESPACE" -o wide
    
    # Check service status
    kubectl get service -n "$NAMESPACE" -o wide
    
    # List AWS load balancers
    log_info "AWS Load Balancers created:"
    aws elbv2 describe-load-balancers \
        --query 'LoadBalancers[?contains(LoadBalancerName, `k8s-`)].{Name:LoadBalancerName,DNS:DNSName,Scheme:Scheme,Type:Type}' \
        --output table 2>/dev/null || log_warning "No load balancers found yet (may still be creating)"
    
    # Get ALB DNS for testing
    log_info "Waiting for ingress to get load balancer address..."
    for i in {1..30}; do
        ALB_DNS=$(kubectl get ingress sample-app-basic-alb -n "$NAMESPACE" \
            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
        if [ -n "$ALB_DNS" ]; then
            break
        fi
        sleep 10
    done
    
    if [ -n "$ALB_DNS" ]; then
        log_success "Basic ALB DNS: $ALB_DNS"
        log_info "Test with: curl -H \"Host: basic.$DOMAIN_NAME\" http://$ALB_DNS/"
    else
        log_warning "ALB DNS not available yet, check status with: kubectl get ingress -n $NAMESPACE"
    fi
    
    log_success "Deployment verification completed"
}

# Save deployment configuration
save_config() {
    local config_file="deployment-config.env"
    
    cat > "$config_file" << EOF
# AWS EKS Ingress Controllers Deployment Configuration
# Generated on $(date)

export AWS_REGION="$AWS_REGION"
export AWS_ACCOUNT_ID="$AWS_ACCOUNT_ID"
export CLUSTER_NAME="$CLUSTER_NAME"
export NAMESPACE="$NAMESPACE"
export DOMAIN_NAME="$DOMAIN_NAME"
export IAM_POLICY_NAME="$IAM_POLICY_NAME"
export SERVICE_ACCOUNT_NAME="$SERVICE_ACCOUNT_NAME"
export HELM_RELEASE_NAME="$HELM_RELEASE_NAME"
export POLICY_ARN="$POLICY_ARN"
EOF
    
    log_success "Configuration saved to $config_file"
    log_info "Source this file to reuse configuration: source $config_file"
}

# Main deployment function
main() {
    log_info "Starting AWS EKS Ingress Controllers deployment..."
    log_info "Timestamp: $(date)"
    
    # Check prerequisites
    check_prerequisites
    
    # Show dry run if requested
    if [ "$DRY_RUN" = true ]; then
        show_dry_run
        exit 0
    fi
    
    # Confirm deployment
    echo
    log_warning "About to deploy AWS EKS Ingress Controllers with the following configuration:"
    echo "  Cluster: $CLUSTER_NAME"
    echo "  Region: $AWS_REGION"
    echo "  Namespace: $NAMESPACE"
    echo "  Domain: $DOMAIN_NAME"
    echo "  Skip cluster creation: $SKIP_CLUSTER_CREATION"
    echo
    read -p "Continue with deployment? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "Deployment cancelled by user"
        exit 0
    fi
    
    # Execute deployment steps
    setup_cluster
    setup_iam
    install_controller
    deploy_applications
    deploy_ingress
    verify_deployment
    save_config
    
    log_success "Deployment completed successfully!"
    echo
    log_info "Next steps:"
    log_info "1. Wait for load balancers to become active (2-3 minutes)"
    log_info "2. Update DNS records to point to load balancer endpoints"
    log_info "3. Test ingress functionality with provided URLs"
    log_info "4. Review CloudWatch logs for troubleshooting if needed"
    echo
    log_warning "Remember to run ./destroy.sh to clean up resources when done"
}

# Run main function
main "$@"