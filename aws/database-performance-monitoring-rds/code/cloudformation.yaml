AWSTemplateFormatVersion: '2010-09-09'
Description: 'Database Performance Monitoring with RDS Performance Insights - Complete infrastructure deployment with advanced monitoring, automated analysis, and intelligent alerting'

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Database Configuration
        Parameters:
          - DBInstanceClass
          - DBEngine
          - DBEngineVersion
          - DBUsername
          - DBPassword
          - AllocatedStorage
          - MultiAZ
      - Label:
          default: Performance Monitoring Configuration
        Parameters:
          - PerformanceInsightsRetentionPeriod
          - MonitoringInterval
          - EnabledCloudwatchLogsExports
      - Label:
          default: Analysis and Alerting Configuration
        Parameters:
          - AnalysisScheduleExpression
          - AlertingEmail
          - CPUThreshold
          - ConnectionsThreshold
          - HighLoadEventsThreshold
          - ProblematicQueriesThreshold
      - Label:
          default: General Configuration
        Parameters:
          - Environment
          - ProjectName
    ParameterLabels:
      DBInstanceClass:
        default: Database Instance Class
      DBEngine:
        default: Database Engine
      DBEngineVersion:
        default: Database Engine Version
      DBUsername:
        default: Database Master Username
      DBPassword:
        default: Database Master Password
      PerformanceInsightsRetentionPeriod:
        default: Performance Insights Retention Period (days)
      MonitoringInterval:
        default: Enhanced Monitoring Interval (seconds)
      AnalysisScheduleExpression:
        default: Automated Analysis Schedule
      AlertingEmail:
        default: Email Address for Alerts

Parameters:
  # Database Configuration Parameters
  DBInstanceClass:
    Type: String
    Default: db.t3.small
    AllowedValues:
      - db.t3.micro
      - db.t3.small
      - db.t3.medium
      - db.t3.large
      - db.t3.xlarge
      - db.t3.2xlarge
      - db.m5.large
      - db.m5.xlarge
      - db.m5.2xlarge
      - db.m5.4xlarge
      - db.r5.large
      - db.r5.xlarge
      - db.r5.2xlarge
      - db.r5.4xlarge
    Description: The database instance class for RDS instance
    ConstraintDescription: Must be a valid RDS instance class

  DBEngine:
    Type: String
    Default: mysql
    AllowedValues:
      - mysql
      - postgres
      - mariadb
      - oracle-ee
      - oracle-se2
      - sqlserver-ex
      - sqlserver-web
      - sqlserver-se
      - sqlserver-ee
    Description: The database engine to use

  DBEngineVersion:
    Type: String
    Default: '8.0.35'
    Description: The database engine version (varies by engine)

  DBUsername:
    Type: String
    Default: admin
    MinLength: 1
    MaxLength: 16
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9]*'
    Description: The database master username
    ConstraintDescription: Must begin with a letter and contain only alphanumeric characters

  DBPassword:
    Type: String
    NoEcho: true
    MinLength: 8
    MaxLength: 41
    AllowedPattern: '[a-zA-Z0-9!@#$%^&*()_+=-]*'
    Description: The database master password
    ConstraintDescription: Must contain 8-41 characters including letters, numbers, and special characters

  AllocatedStorage:
    Type: Number
    Default: 20
    MinValue: 20
    MaxValue: 16384
    Description: The amount of storage to allocate for the database (GB)

  MultiAZ:
    Type: String
    Default: 'false'
    AllowedValues:
      - 'true'
      - 'false'
    Description: Enable Multi-AZ deployment for high availability

  # Performance Monitoring Parameters
  PerformanceInsightsRetentionPeriod:
    Type: Number
    Default: 7
    AllowedValues: [7, 31, 93, 186, 372, 731]
    Description: Performance Insights retention period in days (7 days is free tier)

  MonitoringInterval:
    Type: Number
    Default: 60
    AllowedValues: [0, 1, 5, 10, 15, 30, 60]
    Description: Enhanced monitoring interval in seconds (0 to disable)

  EnabledCloudwatchLogsExports:
    Type: CommaDelimitedList
    Default: 'error,general,slow-query'
    Description: List of log types to export to CloudWatch (comma-separated)

  # Analysis and Alerting Parameters
  AnalysisScheduleExpression:
    Type: String
    Default: 'rate(15 minutes)'
    Description: Schedule expression for automated performance analysis
    AllowedPattern: '^(rate|cron)\(.*\)$'
    ConstraintDescription: Must be a valid rate or cron expression

  AlertingEmail:
    Type: String
    Description: Email address to receive performance alerts
    AllowedPattern: '^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    ConstraintDescription: Must be a valid email address

  CPUThreshold:
    Type: Number
    Default: 75
    MinValue: 1
    MaxValue: 100
    Description: CPU utilization threshold for alerts (percentage)

  ConnectionsThreshold:
    Type: Number
    Default: 80
    MinValue: 1
    MaxValue: 1000
    Description: Database connections threshold for alerts

  HighLoadEventsThreshold:
    Type: Number
    Default: 5
    MinValue: 1
    MaxValue: 100
    Description: High load events threshold for alerts

  ProblematicQueriesThreshold:
    Type: Number
    Default: 3
    MinValue: 1
    MaxValue: 50
    Description: Problematic queries threshold for alerts

  # General Configuration Parameters
  Environment:
    Type: String
    Default: development
    AllowedValues:
      - development
      - staging
      - production
    Description: Environment name for resource tagging

  ProjectName:
    Type: String
    Default: db-performance-monitoring
    Description: Project name for resource naming and tagging
    AllowedPattern: '[a-zA-Z0-9-]*'
    ConstraintDescription: Must contain only alphanumeric characters and hyphens

Conditions:
  # Enable enhanced monitoring if interval is greater than 0
  EnableEnhancedMonitoring: !Not [!Equals [!Ref MonitoringInterval, 0]]
  
  # Enable Multi-AZ if specified
  EnableMultiAZ: !Equals [!Ref MultiAZ, 'true']
  
  # Check if MySQL engine for specific configurations
  IsMySQLEngine: !Equals [!Ref DBEngine, 'mysql']
  
  # Check if PostgreSQL engine for specific configurations
  IsPostgreSQLEngine: !Equals [!Ref DBEngine, 'postgres']
  
  # Production environment checks
  IsProductionEnvironment: !Equals [!Ref Environment, 'production']

Resources:
  # Random suffix for unique naming
  RandomSuffix:
    Type: AWS::CloudFormation::CustomResource
    Properties:
      ServiceToken: !GetAtt RandomSuffixFunction.Arn

  # Lambda function to generate random suffix
  RandomSuffixFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-random-suffix-${AWS::Region}'
      Runtime: python3.9
      Handler: index.handler
      Role: !GetAtt RandomSuffixFunctionRole.Arn
      Timeout: 30
      Code:
        ZipFile: |
          import json
          import random
          import string
          import cfnresponse
          
          def handler(event, context):
              try:
                  if event['RequestType'] == 'Delete':
                      cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                      return
                  
                  # Generate 6-character random suffix
                  suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
                  
                  response_data = {'RandomSuffix': suffix}
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, response_data)
              except Exception as e:
                  print(f"Error: {str(e)}")
                  cfnresponse.send(event, context, cfnresponse.FAILED, {})

  # IAM Role for Random Suffix Function
  RandomSuffixFunctionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole

  # S3 Bucket for Performance Reports
  PerformanceReportsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${ProjectName}-performance-reports-${RandomSuffix.RandomSuffix}'
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      VersioningConfiguration:
        Status: Enabled
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldReports
            Status: Enabled
            ExpirationInDays: 90
            NoncurrentVersionExpirationInDays: 30
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Purpose
          Value: PerformanceReports

  # SNS Topic for Performance Alerts
  PerformanceAlertsTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub '${ProjectName}-performance-alerts-${RandomSuffix.RandomSuffix}'
      DisplayName: Database Performance Alerts
      KmsMasterKeyId: alias/aws/sns
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # SNS Subscription for Email Alerts
  EmailAlertSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      Protocol: email
      TopicArn: !Ref PerformanceAlertsTopic
      Endpoint: !Ref AlertingEmail

  # DB Subnet Group
  DBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupName: !Sub '${ProjectName}-subnet-group-${RandomSuffix.RandomSuffix}'
      DBSubnetGroupDescription: Subnet group for Performance Insights monitoring database
      SubnetIds:
        - !Ref PrivateSubnet1
        - !Ref PrivateSubnet2
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # VPC for Database
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: 10.0.0.0/16
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-vpc'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Internet Gateway
  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-igw'
        - Key: Environment
          Value: !Ref Environment

  # Attach Internet Gateway to VPC
  InternetGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref VPC

  # Private Subnet 1
  PrivateSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [0, !GetAZs '']
      CidrBlock: 10.0.1.0/24
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-private-subnet-1'
        - Key: Environment
          Value: !Ref Environment

  # Private Subnet 2
  PrivateSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [1, !GetAZs '']
      CidrBlock: 10.0.2.0/24
      MapPublicIpOnLaunch: false
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-private-subnet-2'
        - Key: Environment
          Value: !Ref Environment

  # Public Subnet for NAT Gateway
  PublicSubnet:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [0, !GetAZs '']
      CidrBlock: 10.0.3.0/24
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-public-subnet'
        - Key: Environment
          Value: !Ref Environment

  # NAT Gateway for Private Subnet Internet Access
  NATGateway:
    Type: AWS::EC2::NatGateway
    Properties:
      AllocationId: !GetAtt NATGatewayEIP.AllocationId
      SubnetId: !Ref PublicSubnet
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-nat-gateway'
        - Key: Environment
          Value: !Ref Environment

  # Elastic IP for NAT Gateway
  NATGatewayEIP:
    Type: AWS::EC2::EIP
    DependsOn: InternetGatewayAttachment
    Properties:
      Domain: vpc
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-nat-eip'
        - Key: Environment
          Value: !Ref Environment

  # Route Table for Private Subnets
  PrivateRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-private-route-table'
        - Key: Environment
          Value: !Ref Environment

  # Route to NAT Gateway for Private Subnets
  PrivateRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      NatGatewayId: !Ref NATGateway

  # Associate Private Subnet 1 with Private Route Table
  PrivateSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      SubnetId: !Ref PrivateSubnet1

  # Associate Private Subnet 2 with Private Route Table
  PrivateSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PrivateRouteTable
      SubnetId: !Ref PrivateSubnet2

  # Route Table for Public Subnet
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-public-route-table'
        - Key: Environment
          Value: !Ref Environment

  # Route to Internet Gateway for Public Subnet
  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: InternetGatewayAttachment
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  # Associate Public Subnet with Public Route Table
  PublicSubnetRouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref PublicRouteTable
      SubnetId: !Ref PublicSubnet

  # Security Group for RDS Instance
  DatabaseSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub '${ProjectName}-database-sg'
      GroupDescription: Security group for RDS database instance
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: !If [IsMySQLEngine, 3306, !If [IsPostgreSQLEngine, 5432, 1433]]
          ToPort: !If [IsMySQLEngine, 3306, !If [IsPostgreSQLEngine, 5432, 1433]]
          SourceSecurityGroupId: !Ref LambdaSecurityGroup
          Description: Allow Lambda function access to database
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
          Description: Allow all outbound traffic
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-database-sg'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Security Group for Lambda Functions
  LambdaSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: !Sub '${ProjectName}-lambda-sg'
      GroupDescription: Security group for Lambda functions
      VpcId: !Ref VPC
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
          Description: Allow all outbound traffic
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-lambda-sg'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # IAM Role for Enhanced Monitoring
  RDSEnhancedMonitoringRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-rds-monitoring-role-${RandomSuffix.RandomSuffix}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: monitoring.rds.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # RDS Database Instance with Performance Insights
  DatabaseInstance:
    Type: AWS::RDS::DBInstance
    DeletionPolicy: Snapshot
    Properties:
      DBInstanceIdentifier: !Sub '${ProjectName}-db-${RandomSuffix.RandomSuffix}'
      DBInstanceClass: !Ref DBInstanceClass
      Engine: !Ref DBEngine
      EngineVersion: !Ref DBEngineVersion
      MasterUsername: !Ref DBUsername
      MasterUserPassword: !Ref DBPassword
      AllocatedStorage: !Ref AllocatedStorage
      StorageType: gp2
      StorageEncrypted: true
      MultiAZ: !Ref EnableMultiAZ
      DBSubnetGroupName: !Ref DBSubnetGroup
      VPCSecurityGroups:
        - !Ref DatabaseSecurityGroup
      # Performance Insights Configuration
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: !Ref PerformanceInsightsRetentionPeriod
      PerformanceInsightsKMSKeyId: alias/aws/rds
      # Enhanced Monitoring Configuration
      MonitoringInterval: !If [EnableEnhancedMonitoring, !Ref MonitoringInterval, !Ref 'AWS::NoValue']
      MonitoringRoleArn: !If [EnableEnhancedMonitoring, !GetAtt RDSEnhancedMonitoringRole.Arn, !Ref 'AWS::NoValue']
      # CloudWatch Logs Configuration
      EnableCloudwatchLogsExports: !Ref EnabledCloudwatchLogsExports
      # Backup Configuration
      BackupRetentionPeriod: !If [IsProductionEnvironment, 7, 1]
      PreferredBackupWindow: '03:00-04:00'
      PreferredMaintenanceWindow: 'sun:04:00-sun:05:00'
      # Deletion Protection
      DeletionProtection: !If [IsProductionEnvironment, true, false]
      # Tags
      Tags:
        - Key: Name
          Value: !Sub '${ProjectName}-database'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: PerformanceInsights
          Value: 'enabled'

  # IAM Role for Performance Analyzer Lambda Function
  PerformanceAnalyzerRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${ProjectName}-performance-analyzer-role-${RandomSuffix.RandomSuffix}'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: PerformanceInsightsAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - pi:DescribeDimensionKeys
                  - pi:GetResourceMetrics
                  - pi:ListAvailableResourceDimensions
                  - pi:ListAvailableResourceMetrics
                  - pi:GetDimensionKeyDetails
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:GetObject
                  - s3:ListBucket
                Resource:
                  - !Sub '${PerformanceReportsBucket}/*'
                  - !GetAtt PerformanceReportsBucket.Arn
              - Effect: Allow
                Action:
                  - cloudwatch:PutMetricData
                Resource: '*'
              - Effect: Allow
                Action:
                  - rds:DescribeDBInstances
                Resource: '*'
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Performance Analyzer Lambda Function
  PerformanceAnalyzerFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub '${ProjectName}-performance-analyzer-${RandomSuffix.RandomSuffix}'
      Runtime: python3.9
      Handler: index.lambda_handler
      Role: !GetAtt PerformanceAnalyzerRole.Arn
      Timeout: 300
      MemorySize: 512
      VpcConfig:
        SecurityGroupIds:
          - !Ref LambdaSecurityGroup
        SubnetIds:
          - !Ref PrivateSubnet1
          - !Ref PrivateSubnet2
      Environment:
        Variables:
          PI_RESOURCE_ID: !GetAtt DatabaseInstance.DbiResourceId
          S3_BUCKET_NAME: !Ref PerformanceReportsBucket
          DB_INSTANCE_ID: !Ref DatabaseInstance
      Code:
        ZipFile: |
          import json
          import boto3
          import datetime
          import os
          from decimal import Decimal
          
          def lambda_handler(event, context):
              pi_client = boto3.client('pi')
              s3_client = boto3.client('s3')
              cloudwatch = boto3.client('cloudwatch')
              
              # Get configuration from environment variables
              resource_id = os.environ.get('PI_RESOURCE_ID')
              bucket_name = os.environ.get('S3_BUCKET_NAME')
              db_instance_id = os.environ.get('DB_INSTANCE_ID')
              
              # Define time range for analysis (last hour)
              end_time = datetime.datetime.utcnow()
              start_time = end_time - datetime.timedelta(hours=1)
              
              try:
                  # Get database load metrics from Performance Insights
                  response = pi_client.get_resource_metrics(
                      ServiceType='RDS',
                      Identifier=resource_id,
                      StartTime=start_time,
                      EndTime=end_time,
                      PeriodInSeconds=300,
                      MetricQueries=[
                          {
                              'Metric': 'db.load.avg',
                              'GroupBy': {'Group': 'db.wait_event', 'Limit': 10}
                          },
                          {
                              'Metric': 'db.load.avg',
                              'GroupBy': {'Group': 'db.sql_tokenized', 'Limit': 10}
                          },
                          {
                              'Metric': 'db.load.avg'
                          }
                      ]
                  )
                  
                  # Analyze performance patterns
                  analysis_results = analyze_performance_data(response, db_instance_id)
                  
                  # Store analysis results in S3
                  timestamp = datetime.datetime.utcnow().strftime('%Y/%m/%d/%H')
                  report_key = f"performance-reports/{timestamp}/analysis-{int(end_time.timestamp())}.json"
                  
                  s3_client.put_object(
                      Bucket=bucket_name,
                      Key=report_key,
                      Body=json.dumps(analysis_results, default=str, indent=2),
                      ContentType='application/json',
                      ServerSideEncryption='AES256'
                  )
                  
                  # Publish custom metrics to CloudWatch
                  publish_custom_metrics(cloudwatch, analysis_results)
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'message': 'Performance analysis completed successfully',
                          'report_location': f's3://{bucket_name}/{report_key}',
                          'analysis_summary': {
                              'high_load_events': len(analysis_results['high_load_events']),
                              'problematic_queries': len(analysis_results['problematic_queries']),
                              'average_load': analysis_results.get('average_load', 0)
                          }
                      })
                  }
                  
              except Exception as e:
                  print(f"Error in performance analysis: {str(e)}")
                  
                  # Publish error metric
                  try:
                      cloudwatch.put_metric_data(
                          Namespace='RDS/PerformanceInsights',
                          MetricData=[
                              {
                                  'MetricName': 'AnalysisErrors',
                                  'Value': 1,
                                  'Unit': 'Count',
                                  'Timestamp': datetime.datetime.utcnow(),
                                  'Dimensions': [
                                      {
                                          'Name': 'DBInstanceIdentifier',
                                          'Value': db_instance_id
                                      }
                                  ]
                              }
                          ]
                      )
                  except Exception as metric_error:
                      print(f"Error publishing error metric: {str(metric_error)}")
                  
                  return {
                      'statusCode': 500,
                      'body': json.dumps({
                          'error': str(e),
                          'message': 'Performance analysis failed'
                      })
                  }
          
          def analyze_performance_data(response, db_instance_id):
              """Analyze Performance Insights data for anomalies and patterns"""
              analysis = {
                  'timestamp': datetime.datetime.utcnow().isoformat(),
                  'db_instance_id': db_instance_id,
                  'metrics_analyzed': len(response['MetricList']),
                  'high_load_events': [],
                  'problematic_queries': [],
                  'wait_events_summary': [],
                  'overall_load': 0,
                  'average_load': 0,
                  'recommendations': []
              }
              
              total_load = 0
              load_count = 0
              
              for metric in response['MetricList']:
                  if not metric.get('DataPoints'):
                      continue
                  
                  # Calculate average load for this metric
                  metric_load = sum(dp['Value'] for dp in metric['DataPoints']) / len(metric['DataPoints'])
                  
                  # Track overall load
                  if 'Dimensions' not in metric['Key']:
                      # This is the overall load metric
                      analysis['overall_load'] = metric_load
                      total_load += metric_load
                      load_count += 1
                  
                  # Analyze wait events
                  if 'Dimensions' in metric['Key'] and 'db.wait_event.name' in metric['Key']['Dimensions']:
                      wait_event = metric['Key']['Dimensions']['db.wait_event.name']
                      
                      analysis['wait_events_summary'].append({
                          'wait_event': wait_event,
                          'average_load': round(metric_load, 3),
                          'max_load': max(dp['Value'] for dp in metric['DataPoints']),
                          'data_points': len(metric['DataPoints'])
                      })
                      
                      # Flag high load events (load > 1.0 is generally concerning)
                      if metric_load > 1.0:
                          analysis['high_load_events'].append({
                              'wait_event': wait_event,
                              'average_load': round(metric_load, 3),
                              'severity': 'high' if metric_load > 2.0 else 'medium'
                          })
                  
                  # Analyze SQL queries
                  if 'Dimensions' in metric['Key'] and 'db.sql_tokenized.statement' in metric['Key']['Dimensions']:
                      sql_statement = metric['Key']['Dimensions']['db.sql_tokenized.statement']
                      
                      # Flag problematic queries (load > 0.5 is worth investigating)
                      if metric_load > 0.5:
                          analysis['problematic_queries'].append({
                              'sql_statement': sql_statement[:500] + '...' if len(sql_statement) > 500 else sql_statement,
                              'average_load': round(metric_load, 3),
                              'severity': 'high' if metric_load > 1.0 else 'medium'
                          })
              
              # Calculate average load
              if load_count > 0:
                  analysis['average_load'] = round(total_load / load_count, 3)
              
              # Generate recommendations based on analysis
              if analysis['high_load_events']:
                  analysis['recommendations'].append({
                      'category': 'wait_events',
                      'priority': 'high',
                      'message': f"Found {len(analysis['high_load_events'])} high load wait events. Investigate database locks, I/O bottlenecks, or resource contention."
                  })
              
              if analysis['problematic_queries']:
                  analysis['recommendations'].append({
                      'category': 'sql_optimization',
                      'priority': 'medium',
                      'message': f"Found {len(analysis['problematic_queries'])} queries with high load. Review query performance, indexing, and execution plans."
                  })
              
              if analysis['average_load'] > 2.0:
                  analysis['recommendations'].append({
                      'category': 'capacity',
                      'priority': 'high',
                      'message': f"Average database load is {analysis['average_load']}, which is high. Consider scaling up the instance or optimizing workload."
                  })
              
              if not analysis['recommendations']:
                  analysis['recommendations'].append({
                      'category': 'status',
                      'priority': 'info',
                      'message': 'Database performance appears normal based on current analysis.'
                  })
              
              return analysis
          
          def publish_custom_metrics(cloudwatch, analysis):
              """Publish custom metrics to CloudWatch for alerting"""
              try:
                  db_instance_id = analysis['db_instance_id']
                  
                  metric_data = [
                      {
                          'MetricName': 'HighLoadEvents',
                          'Value': len(analysis['high_load_events']),
                          'Unit': 'Count',
                          'Timestamp': datetime.datetime.utcnow(),
                          'Dimensions': [
                              {
                                  'Name': 'DBInstanceIdentifier',
                                  'Value': db_instance_id
                              }
                          ]
                      },
                      {
                          'MetricName': 'ProblematicQueries',
                          'Value': len(analysis['problematic_queries']),
                          'Unit': 'Count',
                          'Timestamp': datetime.datetime.utcnow(),
                          'Dimensions': [
                              {
                                  'Name': 'DBInstanceIdentifier',
                                  'Value': db_instance_id
                              }
                          ]
                      },
                      {
                          'MetricName': 'AverageLoad',
                          'Value': analysis['average_load'],
                          'Unit': 'None',
                          'Timestamp': datetime.datetime.utcnow(),
                          'Dimensions': [
                              {
                                  'Name': 'DBInstanceIdentifier',
                                  'Value': db_instance_id
                              }
                          ]
                      },
                      {
                          'MetricName': 'AnalysisSuccess',
                          'Value': 1,
                          'Unit': 'Count',
                          'Timestamp': datetime.datetime.utcnow(),
                          'Dimensions': [
                              {
                                  'Name': 'DBInstanceIdentifier',
                                  'Value': db_instance_id
                              }
                          ]
                      }
                  ]
                  
                  cloudwatch.put_metric_data(
                      Namespace='RDS/PerformanceInsights',
                      MetricData=metric_data
                  )
                  
                  print(f"Published {len(metric_data)} custom metrics to CloudWatch")
                  
              except Exception as e:
                  print(f"Error publishing custom metrics: {str(e)}")
                  raise
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
        - Key: Purpose
          Value: PerformanceAnalysis

  # EventBridge Rule for Automated Analysis
  PerformanceAnalysisRule:
    Type: AWS::Events::Rule
    Properties:
      Name: !Sub '${ProjectName}-performance-analysis-trigger-${RandomSuffix.RandomSuffix}'
      Description: 'Trigger performance analysis Lambda function on schedule'
      ScheduleExpression: !Ref AnalysisScheduleExpression
      State: ENABLED
      Targets:
        - Arn: !GetAtt PerformanceAnalyzerFunction.Arn
          Id: PerformanceAnalyzerTarget
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Permission for EventBridge to invoke Lambda
  PerformanceAnalysisLambdaPermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Ref PerformanceAnalyzerFunction
      Action: lambda:InvokeFunction
      Principal: events.amazonaws.com
      SourceArn: !GetAtt PerformanceAnalysisRule.Arn

  # CloudWatch Alarms for Database Performance
  
  # High CPU Utilization Alarm
  HighCPUAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-HighCPUUtilization-${DatabaseInstance}'
      AlarmDescription: 'High CPU utilization detected on RDS instance'
      MetricName: CPUUtilization
      Namespace: AWS/RDS
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: !Ref CPUThreshold
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DatabaseInstance
      AlarmActions:
        - !Ref PerformanceAlertsTopic
      OKActions:
        - !Ref PerformanceAlertsTopic
      TreatMissingData: notBreaching
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # High Database Connections Alarm
  HighConnectionsAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-HighDatabaseConnections-${DatabaseInstance}'
      AlarmDescription: 'High number of database connections detected'
      MetricName: DatabaseConnections
      Namespace: AWS/RDS
      Statistic: Average
      Period: 300
      EvaluationPeriods: 2
      Threshold: !Ref ConnectionsThreshold
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DatabaseInstance
      AlarmActions:
        - !Ref PerformanceAlertsTopic
      OKActions:
        - !Ref PerformanceAlertsTopic
      TreatMissingData: notBreaching
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # High Load Events Alarm (Custom Metric)
  HighLoadEventsAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-HighLoadEvents-${DatabaseInstance}'
      AlarmDescription: 'High number of database load events detected by Performance Insights analysis'
      MetricName: HighLoadEvents
      Namespace: RDS/PerformanceInsights
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: !Ref HighLoadEventsThreshold
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DatabaseInstance
      AlarmActions:
        - !Ref PerformanceAlertsTopic
      OKActions:
        - !Ref PerformanceAlertsTopic
      TreatMissingData: notBreaching
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Problematic Queries Alarm (Custom Metric)
  ProblematicQueriesAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub '${ProjectName}-ProblematicQueries-${DatabaseInstance}'
      AlarmDescription: 'High number of problematic SQL queries detected by Performance Insights analysis'
      MetricName: ProblematicQueries
      Namespace: RDS/PerformanceInsights
      Statistic: Sum
      Period: 300
      EvaluationPeriods: 2
      Threshold: !Ref ProblematicQueriesThreshold
      ComparisonOperator: GreaterThanThreshold
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DatabaseInstance
      AlarmActions:
        - !Ref PerformanceAlertsTopic
      OKActions:
        - !Ref PerformanceAlertsTopic
      TreatMissingData: notBreaching
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # CloudWatch Anomaly Detection for Database Load
  DatabaseLoadAnomalyDetector:
    Type: AWS::CloudWatch::AnomalyDetector
    Properties:
      MetricName: DatabaseConnections
      Namespace: AWS/RDS
      Stat: Average
      Dimensions:
        - Name: DBInstanceIdentifier
          Value: !Ref DatabaseInstance
      Tags:
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # CloudWatch Dashboard for Performance Monitoring
  PerformanceDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub '${ProjectName}-Performance-${DatabaseInstance}'
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  ["AWS/RDS", "DatabaseConnections", "DBInstanceIdentifier", "${DatabaseInstance}"],
                  [".", "CPUUtilization", ".", "."],
                  [".", "ReadLatency", ".", "."],
                  [".", "WriteLatency", ".", "."]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "RDS Core Performance Metrics",
                "yAxis": {
                  "left": {
                    "min": 0
                  }
                },
                "view": "timeSeries",
                "stacked": false
              }
            },
            {
              "type": "metric",
              "x": 12,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  ["RDS/PerformanceInsights", "HighLoadEvents", "DBInstanceIdentifier", "${DatabaseInstance}"],
                  [".", "ProblematicQueries", ".", "."],
                  [".", "AverageLoad", ".", "."]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "Performance Insights Analysis Results",
                "view": "timeSeries",
                "stacked": false
              }
            },
            {
              "type": "metric",
              "x": 0,
              "y": 6,
              "width": 12,
              "height": 6,
              "properties": {
                "metrics": [
                  ["AWS/RDS", "ReadIOPS", "DBInstanceIdentifier", "${DatabaseInstance}"],
                  [".", "WriteIOPS", ".", "."],
                  [".", "ReadThroughput", ".", "."],
                  [".", "WriteThroughput", ".", "."]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "I/O Performance Metrics",
                "view": "timeSeries",
                "stacked": false
              }
            },
            {
              "type": "log",
              "x": 12,
              "y": 6,
              "width": 12,
              "height": 6,
              "properties": {
                "query": "SOURCE '/aws/rds/instance/${DatabaseInstance}/slowquery'\n| fields @timestamp, @message\n| sort @timestamp desc\n| limit 20",
                "region": "${AWS::Region}",
                "title": "Recent Slow Query Log Entries",
                "view": "table"
              }
            },
            {
              "type": "metric",
              "x": 0,
              "y": 12,
              "width": 24,
              "height": 6,
              "properties": {
                "metrics": [
                  ["AWS/RDS", "FreeStorageSpace", "DBInstanceIdentifier", "${DatabaseInstance}"],
                  [".", "FreeableMemory", ".", "."],
                  [".", "SwapUsage", ".", "."]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "Resource Utilization",
                "view": "timeSeries",
                "stacked": false
              }
            }
          ]
        }

Outputs:
  # Database Information
  DatabaseEndpoint:
    Description: RDS database endpoint
    Value: !GetAtt DatabaseInstance.Endpoint.Address
    Export:
      Name: !Sub '${AWS::StackName}-DatabaseEndpoint'

  DatabasePort:
    Description: RDS database port
    Value: !GetAtt DatabaseInstance.Endpoint.Port
    Export:
      Name: !Sub '${AWS::StackName}-DatabasePort'

  DatabaseInstanceIdentifier:
    Description: RDS database instance identifier
    Value: !Ref DatabaseInstance
    Export:
      Name: !Sub '${AWS::StackName}-DatabaseInstanceIdentifier'

  PerformanceInsightsResourceId:
    Description: Performance Insights resource ID
    Value: !GetAtt DatabaseInstance.DbiResourceId
    Export:
      Name: !Sub '${AWS::StackName}-PerformanceInsightsResourceId'

  # Performance Insights URLs
  PerformanceInsightsDashboardURL:
    Description: Performance Insights dashboard URL
    Value: !Sub 'https://${AWS::Region}.console.aws.amazon.com/rds/home?region=${AWS::Region}#performance-insights-v20206:/resourceId/${DatabaseInstance.DbiResourceId}'
    Export:
      Name: !Sub '${AWS::StackName}-PerformanceInsightsDashboardURL'

  # CloudWatch Information
  CloudWatchDashboardURL:
    Description: CloudWatch dashboard URL
    Value: !Sub 'https://${AWS::Region}.console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#dashboards:name=${ProjectName}-Performance-${DatabaseInstance}'
    Export:
      Name: !Sub '${AWS::StackName}-CloudWatchDashboardURL'

  # S3 Bucket Information
  PerformanceReportsBucket:
    Description: S3 bucket for performance analysis reports
    Value: !Ref PerformanceReportsBucket
    Export:
      Name: !Sub '${AWS::StackName}-PerformanceReportsBucket'

  # SNS Topic Information
  PerformanceAlertsTopicArn:
    Description: SNS topic ARN for performance alerts
    Value: !Ref PerformanceAlertsTopic
    Export:
      Name: !Sub '${AWS::StackName}-PerformanceAlertsTopicArn'

  # Lambda Function Information
  PerformanceAnalyzerFunctionArn:
    Description: Performance analyzer Lambda function ARN
    Value: !GetAtt PerformanceAnalyzerFunction.Arn
    Export:
      Name: !Sub '${AWS::StackName}-PerformanceAnalyzerFunctionArn'

  # VPC Information
  VPCId:
    Description: VPC ID
    Value: !Ref VPC
    Export:
      Name: !Sub '${AWS::StackName}-VPCId'

  # Database Security Group
  DatabaseSecurityGroupId:
    Description: Database security group ID
    Value: !Ref DatabaseSecurityGroup
    Export:
      Name: !Sub '${AWS::StackName}-DatabaseSecurityGroupId'

  # Connection Information
  DatabaseConnectionString:
    Description: Database connection string template
    Value: !Sub |
      Host: ${DatabaseInstance.Endpoint.Address}
      Port: ${DatabaseInstance.Endpoint.Port}
      Database: ${DBEngine}
      Username: ${DBUsername}
      Password: [Use the password you specified during deployment]
    Export:
      Name: !Sub '${AWS::StackName}-DatabaseConnectionString'

  # Analysis Schedule
  AnalysisSchedule:
    Description: Performance analysis schedule
    Value: !Ref AnalysisScheduleExpression
    Export:
      Name: !Sub '${AWS::StackName}-AnalysisSchedule'

  # Random Suffix
  RandomSuffix:
    Description: Random suffix used for resource naming
    Value: !GetAtt RandomSuffix.RandomSuffix
    Export:
      Name: !Sub '${AWS::StackName}-RandomSuffix'