AWSTemplateFormatVersion: '2010-09-09'
Description: >
  Analytics-Optimized Data Storage with Amazon S3 Tables
  
  This template deploys a complete analytics solution using Amazon S3 Tables with Apache Iceberg support,
  integrated with AWS Glue Data Catalog, Amazon Athena, and Amazon QuickSight for comprehensive
  data analytics capabilities. S3 Tables provides purpose-built storage optimized for analytics workloads
  with built-in maintenance operations and up to 3x faster query performance.

Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: "S3 Tables Configuration"
        Parameters:
          - TableBucketName
          - NamespaceName
          - TableName
          - EnableEncryption
          - KMSKeyId
      - Label:
          default: "Analytics Services Configuration"
        Parameters:
          - GlueDatabaseName
          - AthenaWorkGroupName
          - QueryResultsBucketName
      - Label:
          default: "Sample Data Configuration"
        Parameters:
          - CreateSampleData
          - SampleDataBucketName
      - Label:
          default: "Resource Tagging"
        Parameters:
          - Environment
          - ProjectName
    ParameterLabels:
      TableBucketName:
        default: "S3 Table Bucket Name"
      NamespaceName:
        default: "Table Namespace"
      TableName:
        default: "Analytics Table Name"
      EnableEncryption:
        default: "Enable KMS Encryption"
      KMSKeyId:
        default: "KMS Key ID (optional)"
      GlueDatabaseName:
        default: "Glue Database Name"
      AthenaWorkGroupName:
        default: "Athena WorkGroup Name"
      QueryResultsBucketName:
        default: "Athena Query Results Bucket"
      CreateSampleData:
        default: "Create Sample Dataset"
      SampleDataBucketName:
        default: "Sample Data Bucket Name"
      Environment:
        default: "Environment Tag"
      ProjectName:
        default: "Project Name Tag"

Parameters:
  TableBucketName:
    Type: String
    Description: >
      Name for the S3 table bucket that will store Apache Iceberg tables with optimized performance.
      Must be globally unique and follow S3 naming conventions.
    MinLength: 3
    MaxLength: 63
    AllowedPattern: '^[a-z0-9][a-z0-9-]*[a-z0-9]$'
    ConstraintDescription: >
      Must be 3-63 characters, start and end with lowercase letter or number, 
      and contain only lowercase letters, numbers, and hyphens.
    Default: !Sub 'analytics-tables-${AWS::AccountId}-${AWS::Region}'

  NamespaceName:
    Type: String
    Description: >
      Logical namespace for organizing related tables within the table bucket.
      Enables hierarchical data organization and access control.
    MinLength: 1
    MaxLength: 255
    AllowedPattern: '^[a-zA-Z0-9_][a-zA-Z0-9_-]*$'
    ConstraintDescription: >
      Must start with letter, number, or underscore and contain only alphanumeric characters, 
      underscores, and hyphens.
    Default: 'sales_analytics'

  TableName:
    Type: String
    Description: >
      Name for the Apache Iceberg table that will store transaction data with 
      automatic maintenance and optimization features.
    MinLength: 1
    MaxLength: 255
    AllowedPattern: '^[a-zA-Z0-9_][a-zA-Z0-9_-]*$'
    ConstraintDescription: >
      Must start with letter, number, or underscore and contain only alphanumeric characters, 
      underscores, and hyphens.
    Default: 'transaction_data'

  EnableEncryption:
    Type: String
    Description: >
      Enable server-side encryption for S3 Tables using AWS KMS.
      Recommended for production workloads with sensitive data.
    AllowedValues:
      - 'true'
      - 'false'
    Default: 'true'

  KMSKeyId:
    Type: String
    Description: >
      (Optional) KMS Key ID for S3 Tables encryption. If not provided and encryption is enabled,
      AWS managed key will be used. Specify key ID, ARN, alias, or alias ARN.
    Default: ''

  GlueDatabaseName:
    Type: String
    Description: >
      Name for the AWS Glue database that will contain metadata for S3 Tables.
      Enables integration with Athena, EMR, and other analytics services.
    MinLength: 1
    MaxLength: 255
    AllowedPattern: '^[a-z0-9_][a-z0-9_]*$'
    ConstraintDescription: >
      Must start with lowercase letter, number, or underscore and contain only lowercase letters, 
      numbers, and underscores.
    Default: 's3_tables_analytics'

  AthenaWorkGroupName:
    Type: String
    Description: >
      Name for the Amazon Athena workgroup for querying S3 Tables.
      Provides query isolation and result management.
    MinLength: 1
    MaxLength: 128
    AllowedPattern: '^[a-zA-Z0-9._-]+$'
    ConstraintDescription: >
      Must contain only alphanumeric characters, periods, underscores, and hyphens.
    Default: 's3-tables-workgroup'

  QueryResultsBucketName:
    Type: String
    Description: >
      S3 bucket name for storing Athena query results. Must be globally unique.
      Will be created if it doesn't exist.
    MinLength: 3
    MaxLength: 63
    AllowedPattern: '^[a-z0-9][a-z0-9-]*[a-z0-9]$'
    ConstraintDescription: >
      Must be 3-63 characters, start and end with lowercase letter or number, 
      and contain only lowercase letters, numbers, and hyphens.
    Default: !Sub 'athena-query-results-${AWS::AccountId}-${AWS::Region}'

  CreateSampleData:
    Type: String
    Description: >
      Create a sample dataset for testing and demonstration purposes.
      Includes transaction data for analytics validation.
    AllowedValues:
      - 'true'
      - 'false'
    Default: 'true'

  SampleDataBucketName:
    Type: String
    Description: >
      S3 bucket name for storing sample transaction data files.
      Used for data ingestion testing and validation.
    MinLength: 3
    MaxLength: 63
    AllowedPattern: '^[a-z0-9][a-z0-9-]*[a-z0-9]$'
    ConstraintDescription: >
      Must be 3-63 characters, start and end with lowercase letter or number, 
      and contain only lowercase letters, numbers, and hyphens.
    Default: !Sub 'sample-data-${AWS::AccountId}-${AWS::Region}'

  Environment:
    Type: String
    Description: Environment designation for resource tagging and cost allocation
    AllowedValues:
      - development
      - staging
      - production
    Default: development

  ProjectName:
    Type: String
    Description: Project name for resource tagging and organization
    MinLength: 1
    MaxLength: 255
    Default: 'analytics-s3-tables'

Conditions:
  EnableTableEncryption: !Equals [!Ref EnableEncryption, 'true']
  UseCustomKMSKey: !And
    - !Condition EnableTableEncryption
    - !Not [!Equals [!Ref KMSKeyId, '']]
  CreateSampleDataResources: !Equals [!Ref CreateSampleData, 'true']
  
Resources:
  # KMS Key for S3 Tables encryption (if custom key is requested)
  S3TablesKMSKey:
    Type: AWS::KMS::Key
    Condition: EnableTableEncryption
    Properties:
      Description: !Sub 'KMS key for S3 Tables encryption in ${AWS::StackName}'
      KeyPolicy:
        Version: '2012-10-17'
        Statement:
          - Sid: Enable IAM User Permissions
            Effect: Allow
            Principal:
              AWS: !Sub 'arn:aws:iam::${AWS::AccountId}:root'
            Action: 'kms:*'
            Resource: '*'
          - Sid: Allow S3 Tables Service
            Effect: Allow
            Principal:
              Service: s3tables.amazonaws.com
            Action:
              - kms:Decrypt
              - kms:GenerateDataKey
              - kms:ReEncrypt*
              - kms:CreateGrant
              - kms:DescribeKey
            Resource: '*'
            Condition:
              StringEquals:
                'aws:SourceAccount': !Ref 'AWS::AccountId'
          - Sid: Allow Glue Service
            Effect: Allow
            Principal:
              Service: glue.amazonaws.com
            Action:
              - kms:Decrypt
              - kms:DescribeKey
            Resource: '*'
            Condition:
              StringEquals:
                'aws:SourceAccount': !Ref 'AWS::AccountId'
          - Sid: Allow Athena Service
            Effect: Allow
            Principal:
              Service: athena.amazonaws.com
            Action:
              - kms:Decrypt
              - kms:DescribeKey
            Resource: '*'
            Condition:
              StringEquals:
                'aws:SourceAccount': !Ref 'AWS::AccountId'
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-s3tables-key'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  S3TablesKMSKeyAlias:
    Type: AWS::KMS::Alias
    Condition: EnableTableEncryption
    Properties:
      AliasName: !Sub 'alias/${AWS::StackName}-s3tables'
      TargetKeyId: !Ref S3TablesKMSKey

  # S3 Table Bucket - Core storage for Apache Iceberg tables
  AnalyticsTableBucket:
    Type: AWS::S3Tables::TableBucket
    Properties:
      TableBucketName: !Ref TableBucketName
      EncryptionConfiguration: !If
        - EnableTableEncryption
        - Algorithm: KMS
          KMSKeyIdentifier: !If
            - UseCustomKMSKey
            - !Ref KMSKeyId
            - !If
              - EnableTableEncryption
              - !Ref S3TablesKMSKey
              - !Ref 'AWS::NoValue'
        - !Ref 'AWS::NoValue'
      UnreferencedFileRemoval:
        Status: Enabled
        UnreferencedDays: 7

  # IAM Role for S3 Tables to access AWS Glue Data Catalog
  S3TablesGlueIntegrationRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub '${AWS::StackName}-s3tables-glue-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: s3tables.amazonaws.com
            Action: sts:AssumeRole
            Condition:
              StringEquals:
                'aws:SourceAccount': !Ref 'AWS::AccountId'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/S3TablesServiceRolePolicy
      Policies:
        - PolicyName: GlueCatalogAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - glue:GetDatabase
                  - glue:GetTable
                  - glue:GetTables
                  - glue:GetPartition
                  - glue:GetPartitions
                  - glue:CreateTable
                  - glue:UpdateTable
                  - glue:DeleteTable
                  - glue:CreatePartition
                  - glue:UpdatePartition
                  - glue:DeletePartition
                Resource:
                  - !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:catalog'
                  - !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:database/${GlueDatabaseName}'
                  - !Sub 'arn:aws:glue:${AWS::Region}:${AWS::AccountId}:table/${GlueDatabaseName}/*'
        - PolicyName: KMSAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - kms:Decrypt
                  - kms:DescribeKey
                Resource: !If
                  - EnableTableEncryption
                  - !If
                    - UseCustomKMSKey
                    - !Sub 'arn:aws:kms:${AWS::Region}:${AWS::AccountId}:key/${KMSKeyId}'
                    - !GetAtt S3TablesKMSKey.Arn
                  - !Ref 'AWS::NoValue'
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-s3tables-glue-role'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Table Namespace for logical organization
  SalesAnalyticsNamespace:
    Type: AWS::S3Tables::Namespace
    Properties:
      TableBucketARN: !GetAtt AnalyticsTableBucket.TableBucketARN
      Namespace: !Ref NamespaceName
    DependsOn: AnalyticsTableBucket

  # Apache Iceberg Table for transaction data
  TransactionDataTable:
    Type: AWS::S3Tables::Table
    Properties:
      TableBucketARN: !GetAtt AnalyticsTableBucket.TableBucketARN
      Namespace: !Ref NamespaceName
      TableName: !Ref TableName
      OpenTableFormat: ICEBERG
      # Configure automatic maintenance for optimal performance
      Compaction:
        Status: Enabled
      SnapshotManagement:
        MaxSnapshotAge: 7
    DependsOn: SalesAnalyticsNamespace

  # AWS Glue Database for metadata catalog
  AnalyticsGlueDatabase:
    Type: AWS::Glue::Database
    Properties:
      CatalogId: !Ref 'AWS::AccountId'
      DatabaseInput:
        Name: !Ref GlueDatabaseName
        Description: !Sub 'Glue database for S3 Tables analytics in ${AWS::StackName}'
        Parameters:
          'classification': 'iceberg'
          'table_type': 's3_tables'
          'project': !Ref ProjectName
          'environment': !Ref Environment

  # S3 Bucket for Athena query results
  AthenaQueryResultsBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref QueryResultsBucketName
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldQueryResults
            Status: Enabled
            ExpirationInDays: 30
            NoncurrentVersionExpirationInDays: 7
      VersioningConfiguration:
        Status: Enabled
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-athena-results'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Amazon Athena WorkGroup for query management
  S3TablesAthenaWorkGroup:
    Type: AWS::Athena::WorkGroup
    Properties:
      Name: !Ref AthenaWorkGroupName
      Description: !Sub 'Athena workgroup for S3 Tables analytics in ${AWS::StackName}'
      State: ENABLED
      WorkGroupConfiguration:
        ResultConfiguration:
          OutputLocation: !Sub 's3://${AthenaQueryResultsBucket}/'
          EncryptionConfiguration:
            EncryptionOption: SSE_S3
        EnforceWorkGroupConfiguration: true
        PublishCloudWatchMetrics: true
        BytesScannedCutoffPerQuery: 1073741824 # 1GB limit
        RequesterPaysEnabled: false
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-athena-workgroup'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName
    DependsOn: AthenaQueryResultsBucket

  # Sample Data S3 Bucket (conditional)
  SampleDataBucket:
    Type: AWS::S3::Bucket
    Condition: CreateSampleDataResources
    Properties:
      BucketName: !Ref SampleDataBucketName
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
            BucketKeyEnabled: true
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      LifecycleConfiguration:
        Rules:
          - Id: DeleteSampleData
            Status: Enabled
            ExpirationInDays: 90
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-sample-data'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Lambda function for creating sample data (conditional)
  CreateSampleDataFunction:
    Type: AWS::Lambda::Function
    Condition: CreateSampleDataResources
    Properties:
      FunctionName: !Sub '${AWS::StackName}-create-sample-data'
      Description: Creates sample transaction data for S3 Tables analytics testing
      Runtime: python3.11
      Handler: index.lambda_handler
      Role: !GetAtt SampleDataLambdaRole.Arn
      Timeout: 300
      Environment:
        Variables:
          SAMPLE_BUCKET: !Ref SampleDataBucket
          TABLE_BUCKET_ARN: !GetAtt AnalyticsTableBucket.TableBucketARN
          NAMESPACE: !Ref NamespaceName
          TABLE_NAME: !Ref TableName
      Code:
        ZipFile: |
          import json
          import boto3
          import csv
          import io
          import os
          from datetime import datetime, timedelta
          import random
          
          def lambda_handler(event, context):
              s3 = boto3.client('s3')
              bucket = os.environ['SAMPLE_BUCKET']
              
              # Generate sample transaction data
              transactions = []
              regions = ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1']
              products = [501, 502, 503, 504, 505]
              
              for i in range(1, 1001):  # 1000 sample transactions
                  transaction = {
                      'transaction_id': i,
                      'customer_id': 100 + (i % 50),
                      'product_id': random.choice(products),
                      'quantity': random.randint(1, 5),
                      'price': round(random.uniform(10.0, 200.0), 2),
                      'transaction_date': (datetime.now() - timedelta(days=random.randint(0, 30))).strftime('%Y-%m-%d'),
                      'region': random.choice(regions)
                  }
                  transactions.append(transaction)
              
              # Convert to CSV
              output = io.StringIO()
              writer = csv.DictWriter(output, fieldnames=transactions[0].keys())
              writer.writeheader()
              writer.writerows(transactions)
              
              # Upload to S3
              try:
                  s3.put_object(
                      Bucket=bucket,
                      Key='input/sample_transactions.csv',
                      Body=output.getvalue(),
                      ContentType='text/csv'
                  )
                  
                  return {
                      'statusCode': 200,
                      'body': json.dumps({
                          'message': f'Successfully created {len(transactions)} sample transactions',
                          'location': f's3://{bucket}/input/sample_transactions.csv'
                      })
                  }
              except Exception as e:
                  return {
                      'statusCode': 500,
                      'body': json.dumps({
                          'error': str(e)
                      })
                  }
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-sample-data-function'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # IAM Role for Sample Data Lambda
  SampleDataLambdaRole:
    Type: AWS::IAM::Role
    Condition: CreateSampleDataResources
    Properties:
      RoleName: !Sub '${AWS::StackName}-sample-data-lambda-role'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:PutObject
                  - s3:PutObjectAcl
                Resource: !Sub
                  - '${BucketArn}/*'
                  - BucketArn: !GetAtt SampleDataBucket.Arn
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource: !GetAtt SampleDataBucket.Arn
      Tags:
        - Key: Name
          Value: !Sub '${AWS::StackName}-sample-data-lambda-role'
        - Key: Environment
          Value: !Ref Environment
        - Key: Project
          Value: !Ref ProjectName

  # Custom Resource to trigger sample data creation
  TriggerSampleDataCreation:
    Type: AWS::CloudFormation::CustomResource
    Condition: CreateSampleDataResources
    Properties:
      ServiceToken: !GetAtt CreateSampleDataFunction.Arn
      TriggerUpdate: !Ref 'AWS::StackId'
    DependsOn:
      - CreateSampleDataFunction
      - SampleDataBucket

Outputs:
  # S3 Tables Resources
  TableBucketName:
    Description: Name of the S3 table bucket for analytics workloads
    Value: !Ref AnalyticsTableBucket
    Export:
      Name: !Sub '${AWS::StackName}-table-bucket-name'

  TableBucketARN:
    Description: ARN of the S3 table bucket
    Value: !GetAtt AnalyticsTableBucket.TableBucketARN
    Export:
      Name: !Sub '${AWS::StackName}-table-bucket-arn'

  NamespaceName:
    Description: Name of the table namespace for logical organization
    Value: !Ref NamespaceName
    Export:
      Name: !Sub '${AWS::StackName}-namespace-name'

  TableARN:
    Description: ARN of the Apache Iceberg transaction data table
    Value: !GetAtt TransactionDataTable.TableARN
    Export:
      Name: !Sub '${AWS::StackName}-table-arn'

  TableName:
    Description: Name of the analytics table
    Value: !Ref TableName
    Export:
      Name: !Sub '${AWS::StackName}-table-name'

  # Analytics Services
  GlueDatabaseName:
    Description: Name of the Glue database for metadata catalog
    Value: !Ref AnalyticsGlueDatabase
    Export:
      Name: !Sub '${AWS::StackName}-glue-database'

  AthenaWorkGroupName:
    Description: Name of the Athena workgroup for S3 Tables queries
    Value: !Ref S3TablesAthenaWorkGroup
    Export:
      Name: !Sub '${AWS::StackName}-athena-workgroup'

  QueryResultsBucketName:
    Description: S3 bucket for Athena query results
    Value: !Ref AthenaQueryResultsBucket
    Export:
      Name: !Sub '${AWS::StackName}-query-results-bucket'

  # Sample Data Resources (conditional)
  SampleDataBucketName:
    Condition: CreateSampleDataResources
    Description: S3 bucket containing sample transaction data
    Value: !Ref SampleDataBucket
    Export:
      Name: !Sub '${AWS::StackName}-sample-data-bucket'

  SampleDataLocation:
    Condition: CreateSampleDataResources
    Description: S3 location of sample transaction data file
    Value: !Sub 's3://${SampleDataBucket}/input/sample_transactions.csv'
    Export:
      Name: !Sub '${AWS::StackName}-sample-data-location'

  # Security Resources
  KMSKeyId:
    Condition: EnableTableEncryption
    Description: KMS Key ID for S3 Tables encryption
    Value: !Ref S3TablesKMSKey
    Export:
      Name: !Sub '${AWS::StackName}-kms-key-id'

  KMSKeyAlias:
    Condition: EnableTableEncryption
    Description: KMS Key Alias for S3 Tables encryption
    Value: !Ref S3TablesKMSKeyAlias
    Export:
      Name: !Sub '${AWS::StackName}-kms-key-alias'

  # Quick Start Commands
  AthenaQueryCommand:
    Description: Sample Athena query command to test the S3 Tables setup
    Value: !Sub |
      aws athena start-query-execution \
        --query-string "SELECT COUNT(*) FROM \"${GlueDatabaseName}\".\"${TableName}\"" \
        --work-group ${AthenaWorkGroupName} \
        --result-configuration OutputLocation=s3://${AthenaQueryResultsBucket}/

  S3TablesListCommand:
    Description: CLI command to list tables in the namespace
    Value: !Sub |
      aws s3tables list-tables \
        --table-bucket-arn ${AnalyticsTableBucket.TableBucketARN} \
        --namespace ${NamespaceName}

  QuickSightDataSourceURL:
    Description: Information for connecting QuickSight to the analytics data
    Value: !Sub |
      Data Source Type: Amazon Athena
      Workgroup: ${AthenaWorkGroupName}
      Database: ${GlueDatabaseName}
      Query Result Location: s3://${AthenaQueryResultsBucket}/

  # Cost Optimization Notes
  EstimatedMonthlyCost:
    Description: Estimated monthly cost for moderate usage (reference only)
    Value: |
      S3 Tables Storage: ~$35/TB/month + requests
      Athena Queries: $5/TB scanned
      Glue Catalog: $1/100k requests
      KMS: $1/month + $0.03/10k requests
      See AWS Pricing Calculator for detailed estimates

  OptimizationTips:
    Description: Tips for cost optimization
    Value: |
      1. Use partitioning to reduce data scanned by queries
      2. Enable S3 Tables compaction for storage efficiency
      3. Set appropriate Athena query limits in workgroup
      4. Monitor usage with AWS Cost Explorer
      5. Use S3 lifecycle policies for query results cleanup